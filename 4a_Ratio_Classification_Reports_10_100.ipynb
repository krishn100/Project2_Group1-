{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.3.4'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n      require([\"jspanel\"], function(jsPanel) {\n\twindow.jsPanel = jsPanel\n\ton_load()\n      })\n      require([\"jspanel-modal\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-tooltip\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-hint\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-layout\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-contextmenu\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-dock\"], function() {\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 9;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.4.min.js\", \"https://cdn.holoviz.org/panel/1.3.8/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n\ttry {\n          inline_js[i].call(root, root.Bokeh);\n\t} catch(e) {\n\t  if (!reloading) {\n\t    throw e;\n\t  }\n\t}\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='p1002'>\n",
       "  <div id=\"b2b63832-baf8-49db-bad0-40b68adb27d7\" data-root-id=\"p1002\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"9df3f81e-2253-4d13-afb0-5d0b8d9eef34\":{\"version\":\"3.3.4\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"p1002\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"p1003\",\"attributes\":{\"plot_id\":\"p1002\",\"comm_id\":\"6a9d4f0aae9c4c13a3ab1690c5a93d8c\",\"client_comm_id\":\"d69e599b79af4a5c8d3d093ca200c8dd\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"copy_to_clipboard1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
       "  var render_items = [{\"docid\":\"9df3f81e-2253-4d13-afb0-5d0b8d9eef34\",\"roots\":{\"p1002\":\"b2b63832-baf8-49db-bad0-40b68adb27d7\"},\"root_ids\":[\"p1002\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && (id_el.children[0].className === 'bk-root')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "p1002"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "from pathlib import Path\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_rows', None)  # To show all rows\n",
    "pd.set_option('display.max_columns', None)  # To show all columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GOOGLE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the CSV files that contain SMA, EMA, and BB/RSI inidcators based on ratio data\n",
    "googl_df = pd.read_csv(\"Resources/googl_signals.csv\", infer_datetime_format=True, index_col=\"Date\", parse_dates=True)\n",
    "nvda_df = pd.read_csv(\"Resources/nvda_signals.csv\", infer_datetime_format=True, index_col=\"Date\", parse_dates=True)\n",
    "mmm_df = pd.read_csv(\"Resources/mmm_signals.csv\", infer_datetime_format=True, index_col=\"Date\", parse_dates=True)\n",
    "pg_df = pd.read_csv(\"Resources/pg_signals.csv\", infer_datetime_format=True, index_col=\"Date\", parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for machine learning, scaling, resampling and classification reports \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.combine import SMOTEENN\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) \n",
    "features = ['GOOGL P/S (LTM)', 'GOOGL P/FCF (LTM)', 'GOOGL P/E (LTM)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define y variables\n",
    "y_variables = ['ps_Entry/Exit_sma', 'ps_Entry/Exit_ema', 'pfcf_Entry/Exit_sma',\n",
    "               'pfcf_Entry/Exit_ema', 'pe_Entry/Exit_sma', 'pe_Entry/Exit_ema']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Classification reports for 'ps_Entry/Exit_sma' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.34      0.10      0.15       242\n",
      "         0.0       0.52      0.48      0.50       221\n",
      "         1.0       0.39      0.75      0.51       205\n",
      "\n",
      "    accuracy                           0.42       668\n",
      "   macro avg       0.42      0.44      0.39       668\n",
      "weighted avg       0.41      0.42      0.37       668\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.33      0.10      0.16       863\n",
      "         0.0       0.46      0.44      0.45       887\n",
      "         1.0       0.41      0.70      0.52       921\n",
      "\n",
      "    accuracy                           0.42      2671\n",
      "   macro avg       0.40      0.41      0.37      2671\n",
      "weighted avg       0.40      0.42      0.38      2671\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.97      0.98      0.97       242\n",
      "         0.0       1.00      0.96      0.98       221\n",
      "         1.0       0.97      1.00      0.98       205\n",
      "\n",
      "    accuracy                           0.98       668\n",
      "   macro avg       0.98      0.98      0.98       668\n",
      "weighted avg       0.98      0.98      0.98       668\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       863\n",
      "         0.0       1.00      1.00      1.00       887\n",
      "         1.0       1.00      1.00      1.00       921\n",
      "\n",
      "    accuracy                           1.00      2671\n",
      "   macro avg       1.00      1.00      1.00      2671\n",
      "weighted avg       1.00      1.00      1.00      2671\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.62      0.15      0.25       242\n",
      "         0.0       0.41      0.52      0.46       221\n",
      "         1.0       0.37      0.60      0.46       205\n",
      "\n",
      "    accuracy                           0.41       668\n",
      "   macro avg       0.47      0.42      0.39       668\n",
      "weighted avg       0.47      0.41      0.38       668\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.52      0.11      0.18       863\n",
      "         0.0       0.41      0.56      0.47       887\n",
      "         1.0       0.41      0.58      0.48       921\n",
      "\n",
      "    accuracy                           0.42      2671\n",
      "   macro avg       0.45      0.41      0.38      2671\n",
      "weighted avg       0.45      0.42      0.38      2671\n",
      "\n",
      "\n",
      "--- Classification reports for 'ps_Entry/Exit_ema' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.40      0.31      0.35       255\n",
      "         0.0       0.53      0.40      0.46       202\n",
      "         1.0       0.37      0.56      0.45       218\n",
      "\n",
      "    accuracy                           0.42       675\n",
      "   macro avg       0.43      0.42      0.42       675\n",
      "weighted avg       0.43      0.42      0.41       675\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.37      0.34      0.35       916\n",
      "         0.0       0.51      0.41      0.46       889\n",
      "         1.0       0.38      0.49      0.43       895\n",
      "\n",
      "    accuracy                           0.41      2700\n",
      "   macro avg       0.42      0.42      0.41      2700\n",
      "weighted avg       0.42      0.41      0.41      2700\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.98      1.00      0.99       255\n",
      "         0.0       0.99      0.98      0.99       202\n",
      "         1.0       0.99      0.98      0.98       218\n",
      "\n",
      "    accuracy                           0.99       675\n",
      "   macro avg       0.99      0.99      0.99       675\n",
      "weighted avg       0.99      0.99      0.99       675\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       916\n",
      "         0.0       1.00      1.00      1.00       889\n",
      "         1.0       1.00      1.00      1.00       895\n",
      "\n",
      "    accuracy                           1.00      2700\n",
      "   macro avg       1.00      1.00      1.00      2700\n",
      "weighted avg       1.00      1.00      1.00      2700\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.37      0.38      0.38       255\n",
      "         0.0       0.36      0.23      0.28       202\n",
      "         1.0       0.27      0.35      0.31       218\n",
      "\n",
      "    accuracy                           0.33       675\n",
      "   macro avg       0.33      0.32      0.32       675\n",
      "weighted avg       0.34      0.33      0.33       675\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.36      0.43      0.39       916\n",
      "         0.0       0.37      0.24      0.29       889\n",
      "         1.0       0.30      0.34      0.32       895\n",
      "\n",
      "    accuracy                           0.34      2700\n",
      "   macro avg       0.34      0.34      0.33      2700\n",
      "weighted avg       0.34      0.34      0.33      2700\n",
      "\n",
      "\n",
      "--- Classification reports for 'pfcf_Entry/Exit_sma' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.55      0.26      0.35       249\n",
      "         0.0       0.44      0.40      0.42       205\n",
      "         1.0       0.38      0.67      0.49       201\n",
      "\n",
      "    accuracy                           0.43       655\n",
      "   macro avg       0.46      0.44      0.42       655\n",
      "weighted avg       0.47      0.43      0.42       655\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.46      0.26      0.33       841\n",
      "         0.0       0.47      0.38      0.42       883\n",
      "         1.0       0.43      0.69      0.53       892\n",
      "\n",
      "    accuracy                           0.45      2616\n",
      "   macro avg       0.45      0.44      0.43      2616\n",
      "weighted avg       0.45      0.45      0.43      2616\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.98      0.98      0.98       249\n",
      "         0.0       0.97      0.96      0.97       205\n",
      "         1.0       0.98      0.99      0.99       201\n",
      "\n",
      "    accuracy                           0.98       655\n",
      "   macro avg       0.98      0.98      0.98       655\n",
      "weighted avg       0.98      0.98      0.98       655\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       841\n",
      "         0.0       1.00      1.00      1.00       883\n",
      "         1.0       1.00      1.00      1.00       892\n",
      "\n",
      "    accuracy                           1.00      2616\n",
      "   macro avg       1.00      1.00      1.00      2616\n",
      "weighted avg       1.00      1.00      1.00      2616\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.49      0.22      0.31       249\n",
      "         0.0       0.47      0.57      0.52       205\n",
      "         1.0       0.38      0.55      0.45       201\n",
      "\n",
      "    accuracy                           0.43       655\n",
      "   macro avg       0.45      0.45      0.42       655\n",
      "weighted avg       0.45      0.43      0.42       655\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.32      0.17      0.23       841\n",
      "         0.0       0.47      0.56      0.51       883\n",
      "         1.0       0.44      0.55      0.49       892\n",
      "\n",
      "    accuracy                           0.43      2616\n",
      "   macro avg       0.41      0.43      0.41      2616\n",
      "weighted avg       0.41      0.43      0.41      2616\n",
      "\n",
      "\n",
      "--- Classification reports for 'pfcf_Entry/Exit_ema' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.61      0.42      0.50       250\n",
      "         0.0       0.35      0.49      0.41       184\n",
      "         1.0       0.60      0.61      0.61       209\n",
      "\n",
      "    accuracy                           0.50       643\n",
      "   macro avg       0.52      0.51      0.51       643\n",
      "weighted avg       0.53      0.50      0.51       643\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.60      0.43      0.50       873\n",
      "         0.0       0.42      0.52      0.47       856\n",
      "         1.0       0.58      0.63      0.61       843\n",
      "\n",
      "    accuracy                           0.52      2572\n",
      "   macro avg       0.54      0.52      0.52      2572\n",
      "weighted avg       0.54      0.52      0.52      2572\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      0.98      0.99       250\n",
      "         0.0       0.98      0.99      0.99       184\n",
      "         1.0       0.98      0.99      0.99       209\n",
      "\n",
      "    accuracy                           0.99       643\n",
      "   macro avg       0.99      0.99      0.99       643\n",
      "weighted avg       0.99      0.99      0.99       643\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       873\n",
      "         0.0       1.00      1.00      1.00       856\n",
      "         1.0       1.00      1.00      1.00       843\n",
      "\n",
      "    accuracy                           1.00      2572\n",
      "   macro avg       1.00      1.00      1.00      2572\n",
      "weighted avg       1.00      1.00      1.00      2572\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.48      0.64      0.55       250\n",
      "         0.0       0.43      0.64      0.51       184\n",
      "         1.0       0.56      0.11      0.18       209\n",
      "\n",
      "    accuracy                           0.47       643\n",
      "   macro avg       0.49      0.46      0.41       643\n",
      "weighted avg       0.49      0.47      0.42       643\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.43      0.63      0.51       873\n",
      "         0.0       0.48      0.64      0.55       856\n",
      "         1.0       0.55      0.10      0.17       843\n",
      "\n",
      "    accuracy                           0.46      2572\n",
      "   macro avg       0.49      0.46      0.41      2572\n",
      "weighted avg       0.49      0.46      0.41      2572\n",
      "\n",
      "\n",
      "--- Classification reports for 'pe_Entry/Exit_sma' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.33      0.13      0.19       216\n",
      "         0.0       0.49      0.42      0.45       208\n",
      "         1.0       0.44      0.79      0.57       206\n",
      "\n",
      "    accuracy                           0.44       630\n",
      "   macro avg       0.42      0.45      0.40       630\n",
      "weighted avg       0.42      0.44      0.40       630\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.37      0.14      0.21       778\n",
      "         0.0       0.50      0.40      0.44       875\n",
      "         1.0       0.48      0.84      0.61       866\n",
      "\n",
      "    accuracy                           0.47      2519\n",
      "   macro avg       0.45      0.46      0.42      2519\n",
      "weighted avg       0.45      0.47      0.43      2519\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.98      0.98      0.98       216\n",
      "         0.0       0.98      0.98      0.98       208\n",
      "         1.0       0.99      0.99      0.99       206\n",
      "\n",
      "    accuracy                           0.98       630\n",
      "   macro avg       0.98      0.98      0.98       630\n",
      "weighted avg       0.98      0.98      0.98       630\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       778\n",
      "         0.0       1.00      1.00      1.00       875\n",
      "         1.0       1.00      1.00      1.00       866\n",
      "\n",
      "    accuracy                           1.00      2519\n",
      "   macro avg       1.00      1.00      1.00      2519\n",
      "weighted avg       1.00      1.00      1.00      2519\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.45      0.39      0.42       216\n",
      "         0.0       0.38      0.40      0.39       208\n",
      "         1.0       0.49      0.53      0.51       206\n",
      "\n",
      "    accuracy                           0.44       630\n",
      "   macro avg       0.44      0.44      0.44       630\n",
      "weighted avg       0.44      0.44      0.44       630\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.40      0.41      0.40       778\n",
      "         0.0       0.40      0.38      0.39       875\n",
      "         1.0       0.49      0.50      0.49       866\n",
      "\n",
      "    accuracy                           0.43      2519\n",
      "   macro avg       0.43      0.43      0.43      2519\n",
      "weighted avg       0.43      0.43      0.43      2519\n",
      "\n",
      "\n",
      "--- Classification reports for 'pe_Entry/Exit_ema' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.55      0.71      0.62       241\n",
      "         0.0       0.55      0.40      0.46       202\n",
      "         1.0       0.54      0.50      0.52       208\n",
      "\n",
      "    accuracy                           0.55       651\n",
      "   macro avg       0.55      0.54      0.53       651\n",
      "weighted avg       0.55      0.55      0.54       651\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.44      0.66      0.53       820\n",
      "         0.0       0.61      0.41      0.49       888\n",
      "         1.0       0.51      0.45      0.48       895\n",
      "\n",
      "    accuracy                           0.50      2603\n",
      "   macro avg       0.52      0.51      0.50      2603\n",
      "weighted avg       0.52      0.50      0.50      2603\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      0.98      0.99       241\n",
      "         0.0       0.98      0.99      0.98       202\n",
      "         1.0       0.97      1.00      0.98       208\n",
      "\n",
      "    accuracy                           0.98       651\n",
      "   macro avg       0.98      0.99      0.98       651\n",
      "weighted avg       0.98      0.98      0.98       651\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       820\n",
      "         0.0       1.00      1.00      1.00       888\n",
      "         1.0       1.00      1.00      1.00       895\n",
      "\n",
      "    accuracy                           1.00      2603\n",
      "   macro avg       1.00      1.00      1.00      2603\n",
      "weighted avg       1.00      1.00      1.00      2603\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.43      0.44      0.44       241\n",
      "         0.0       0.33      0.33      0.33       202\n",
      "         1.0       0.44      0.43      0.44       208\n",
      "\n",
      "    accuracy                           0.40       651\n",
      "   macro avg       0.40      0.40      0.40       651\n",
      "weighted avg       0.40      0.40      0.40       651\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.35      0.40      0.38       820\n",
      "         0.0       0.33      0.31      0.32       888\n",
      "         1.0       0.41      0.37      0.39       895\n",
      "\n",
      "    accuracy                           0.36      2603\n",
      "   macro avg       0.36      0.36      0.36      2603\n",
      "weighted avg       0.36      0.36      0.36      2603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define models\n",
    "logistic_regression = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "models = {'Naive Bayes': GaussianNB(),\n",
    "          'Random Forest Classifier': RandomForestClassifier(random_state=42),\n",
    "          'Logistic Regression': logistic_regression}\n",
    "\n",
    "# Create an empty DataFrame to store the classification reports\n",
    "reports_df_test = pd.DataFrame()\n",
    "reports_df_train = pd.DataFrame()\n",
    "\n",
    "# Loop through each y variable\n",
    "for y_var in y_variables:\n",
    "    print(f\"\\n--- Classification reports for '{y_var}' ---\\n\")\n",
    "    \n",
    "    # Drop NaN values from X and y for the current y variable\n",
    "    data_cleaned = googl_df.dropna(subset=features + [y_var])\n",
    "    X = data_cleaned[features]\n",
    "    y = data_cleaned[y_var]\n",
    "\n",
    "    # Apply SMOTEENN to address class imbalance\n",
    "    smoteenn = SMOTEENN(random_state=42)\n",
    "    X_resampled, y_resampled = smoteenn.fit_resample(X, y)\n",
    "\n",
    "    # Split the resampled data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Scale the features using StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Loop through each model\n",
    "    for model_name, model in models.items():\n",
    "        # Train the model on the training data\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "\n",
    "        # Make predictions on the testing data\n",
    "        y_pred_test = model.predict(X_test_scaled)\n",
    "\n",
    "        # Print label for the model\n",
    "        print(f\"\\n--- {model_name} --- (Testing Data)\")\n",
    "\n",
    "        # Print classification report for testing data\n",
    "        print(classification_report(y_test, y_pred_test))\n",
    "        \n",
    "        # Store classification report for testing data in the DataFrame\n",
    "        report_test = classification_report(y_test, y_pred_test, output_dict=True)\n",
    "        report_df_test = pd.DataFrame(report_test).transpose()\n",
    "        report_df_test['y_variable'] = y_var\n",
    "        report_df_test['model'] = model_name\n",
    "        reports_df_test = pd.concat([reports_df_test, report_df_test])\n",
    "\n",
    "        # Make predictions on the training data\n",
    "        y_pred_train = model.predict(X_train_scaled)\n",
    "\n",
    "        # Print label for the model\n",
    "        print(f\"\\n--- {model_name} --- (Training Data)\")\n",
    "\n",
    "        # Print classification report for training data\n",
    "        print(classification_report(y_train, y_pred_train))\n",
    "\n",
    "        # Store classification report for training data in the DataFrame\n",
    "        report_train = classification_report(y_train, y_pred_train, output_dict=True)\n",
    "        report_df_train = pd.DataFrame(report_train).transpose()\n",
    "        report_df_train['y_variable'] = y_var\n",
    "        report_df_train['model'] = model_name\n",
    "        reports_df_train = pd.concat([reports_df_train, report_df_train])\n",
    "\n",
    "# Export the DataFrames containing classification reports to separate CSV files\n",
    "reports_df_test.to_csv('testing_classification_reports_GOOGLE_10.csv', index=True)\n",
    "reports_df_train.to_csv('training_classification_reports_GOOGLE_10.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NVDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X)\n",
    "features = ['NVDA P/S (LTM)', 'NVDA P/FCF (LTM)', 'NVDA P/E (LTM)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define y variables\n",
    "y_variables = ['ps_Entry/Exit_sma', 'ps_Entry/Exit_ema', 'pfcf_Entry/Exit_sma',\n",
    "               'pfcf_Entry/Exit_ema', 'pe_Entry/Exit_sma', 'pe_Entry/Exit_ema']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Classification reports for 'ps_Entry/Exit_sma' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.49      0.84      0.62       238\n",
      "         0.0       0.52      0.39      0.45       201\n",
      "         1.0       0.11      0.04      0.06       193\n",
      "\n",
      "    accuracy                           0.45       632\n",
      "   macro avg       0.37      0.42      0.37       632\n",
      "weighted avg       0.38      0.45      0.39       632\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.44      0.83      0.57       851\n",
      "         0.0       0.52      0.38      0.44       852\n",
      "         1.0       0.16      0.06      0.09       824\n",
      "\n",
      "    accuracy                           0.43      2527\n",
      "   macro avg       0.37      0.42      0.37      2527\n",
      "weighted avg       0.38      0.43      0.37      2527\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.97      0.98      0.98       238\n",
      "         0.0       0.99      0.96      0.97       201\n",
      "         1.0       0.97      0.99      0.98       193\n",
      "\n",
      "    accuracy                           0.98       632\n",
      "   macro avg       0.98      0.98      0.98       632\n",
      "weighted avg       0.98      0.98      0.98       632\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       851\n",
      "         0.0       1.00      1.00      1.00       852\n",
      "         1.0       1.00      1.00      1.00       824\n",
      "\n",
      "    accuracy                           1.00      2527\n",
      "   macro avg       1.00      1.00      1.00      2527\n",
      "weighted avg       1.00      1.00      1.00      2527\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.35      0.41      0.38       238\n",
      "         0.0       0.24      0.30      0.27       201\n",
      "         1.0       0.12      0.06      0.08       193\n",
      "\n",
      "    accuracy                           0.27       632\n",
      "   macro avg       0.24      0.26      0.24       632\n",
      "weighted avg       0.24      0.27      0.25       632\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.30      0.38      0.33       851\n",
      "         0.0       0.26      0.31      0.28       852\n",
      "         1.0       0.17      0.09      0.12       824\n",
      "\n",
      "    accuracy                           0.26      2527\n",
      "   macro avg       0.24      0.26      0.24      2527\n",
      "weighted avg       0.24      0.26      0.24      2527\n",
      "\n",
      "\n",
      "--- Classification reports for 'ps_Entry/Exit_ema' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.54      0.77      0.63       217\n",
      "         0.0       0.66      0.39      0.49       205\n",
      "         1.0       0.45      0.43      0.44       183\n",
      "\n",
      "    accuracy                           0.54       605\n",
      "   macro avg       0.55      0.53      0.52       605\n",
      "weighted avg       0.55      0.54      0.53       605\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.50      0.78      0.61       780\n",
      "         0.0       0.66      0.35      0.46       823\n",
      "         1.0       0.46      0.43      0.44       815\n",
      "\n",
      "    accuracy                           0.51      2418\n",
      "   macro avg       0.54      0.52      0.50      2418\n",
      "weighted avg       0.54      0.51      0.50      2418\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.99      0.99      0.99       217\n",
      "         0.0       0.98      0.99      0.98       205\n",
      "         1.0       0.98      0.97      0.98       183\n",
      "\n",
      "    accuracy                           0.98       605\n",
      "   macro avg       0.98      0.98      0.98       605\n",
      "weighted avg       0.98      0.98      0.98       605\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       780\n",
      "         0.0       1.00      1.00      1.00       823\n",
      "         1.0       1.00      1.00      1.00       815\n",
      "\n",
      "    accuracy                           1.00      2418\n",
      "   macro avg       1.00      1.00      1.00      2418\n",
      "weighted avg       1.00      1.00      1.00      2418\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.54      0.40      0.46       217\n",
      "         0.0       0.32      0.44      0.37       205\n",
      "         1.0       0.43      0.38      0.40       183\n",
      "\n",
      "    accuracy                           0.41       605\n",
      "   macro avg       0.43      0.41      0.41       605\n",
      "weighted avg       0.43      0.41      0.41       605\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.49      0.41      0.45       780\n",
      "         0.0       0.32      0.45      0.38       823\n",
      "         1.0       0.46      0.36      0.40       815\n",
      "\n",
      "    accuracy                           0.41      2418\n",
      "   macro avg       0.43      0.41      0.41      2418\n",
      "weighted avg       0.43      0.41      0.41      2418\n",
      "\n",
      "\n",
      "--- Classification reports for 'pfcf_Entry/Exit_sma' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.58      0.69      0.63       253\n",
      "         0.0       0.66      0.49      0.56       202\n",
      "         1.0       0.48      0.49      0.49       209\n",
      "\n",
      "    accuracy                           0.57       664\n",
      "   macro avg       0.58      0.56      0.56       664\n",
      "weighted avg       0.58      0.57      0.57       664\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.57      0.70      0.63       916\n",
      "         0.0       0.70      0.51      0.59       893\n",
      "         1.0       0.52      0.55      0.54       847\n",
      "\n",
      "    accuracy                           0.59      2656\n",
      "   macro avg       0.60      0.59      0.59      2656\n",
      "weighted avg       0.60      0.59      0.59      2656\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.98      0.97      0.98       253\n",
      "         0.0       0.98      0.98      0.98       202\n",
      "         1.0       0.95      0.97      0.96       209\n",
      "\n",
      "    accuracy                           0.97       664\n",
      "   macro avg       0.97      0.97      0.97       664\n",
      "weighted avg       0.97      0.97      0.97       664\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       916\n",
      "         0.0       1.00      1.00      1.00       893\n",
      "         1.0       1.00      1.00      1.00       847\n",
      "\n",
      "    accuracy                           1.00      2656\n",
      "   macro avg       1.00      1.00      1.00      2656\n",
      "weighted avg       1.00      1.00      1.00      2656\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.49      0.79      0.61       253\n",
      "         0.0       0.46      0.47      0.46       202\n",
      "         1.0       0.28      0.07      0.11       209\n",
      "\n",
      "    accuracy                           0.47       664\n",
      "   macro avg       0.41      0.44      0.39       664\n",
      "weighted avg       0.42      0.47      0.41       664\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.47      0.79      0.59       916\n",
      "         0.0       0.49      0.51      0.50       893\n",
      "         1.0       0.30      0.07      0.11       847\n",
      "\n",
      "    accuracy                           0.47      2656\n",
      "   macro avg       0.42      0.46      0.40      2656\n",
      "weighted avg       0.42      0.47      0.41      2656\n",
      "\n",
      "\n",
      "--- Classification reports for 'pfcf_Entry/Exit_ema' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.41      0.46      0.43       251\n",
      "         0.0       0.64      0.35      0.45       198\n",
      "         1.0       0.32      0.42      0.36       192\n",
      "\n",
      "    accuracy                           0.41       641\n",
      "   macro avg       0.46      0.41      0.42       641\n",
      "weighted avg       0.45      0.41      0.42       641\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.38      0.50      0.43       889\n",
      "         0.0       0.68      0.35      0.46       853\n",
      "         1.0       0.39      0.45      0.42       822\n",
      "\n",
      "    accuracy                           0.44      2564\n",
      "   macro avg       0.48      0.43      0.44      2564\n",
      "weighted avg       0.48      0.44      0.44      2564\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.99      0.97      0.98       251\n",
      "         0.0       0.97      0.97      0.97       198\n",
      "         1.0       0.95      0.98      0.96       192\n",
      "\n",
      "    accuracy                           0.97       641\n",
      "   macro avg       0.97      0.97      0.97       641\n",
      "weighted avg       0.97      0.97      0.97       641\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       889\n",
      "         0.0       1.00      1.00      1.00       853\n",
      "         1.0       1.00      1.00      1.00       822\n",
      "\n",
      "    accuracy                           1.00      2564\n",
      "   macro avg       1.00      1.00      1.00      2564\n",
      "weighted avg       1.00      1.00      1.00      2564\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.44      0.47      0.45       251\n",
      "         0.0       0.44      0.32      0.37       198\n",
      "         1.0       0.36      0.44      0.40       192\n",
      "\n",
      "    accuracy                           0.41       641\n",
      "   macro avg       0.42      0.41      0.41       641\n",
      "weighted avg       0.42      0.41      0.41       641\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.41      0.48      0.44       889\n",
      "         0.0       0.49      0.32      0.39       853\n",
      "         1.0       0.37      0.44      0.40       822\n",
      "\n",
      "    accuracy                           0.41      2564\n",
      "   macro avg       0.42      0.41      0.41      2564\n",
      "weighted avg       0.42      0.41      0.41      2564\n",
      "\n",
      "\n",
      "--- Classification reports for 'pe_Entry/Exit_sma' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.74      0.54      0.63       259\n",
      "         0.0       0.63      0.58      0.60       212\n",
      "         1.0       0.60      0.85      0.70       207\n",
      "\n",
      "    accuracy                           0.65       678\n",
      "   macro avg       0.66      0.66      0.64       678\n",
      "weighted avg       0.66      0.65      0.64       678\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.70      0.53      0.61       930\n",
      "         0.0       0.64      0.53      0.58       898\n",
      "         1.0       0.59      0.84      0.70       881\n",
      "\n",
      "    accuracy                           0.63      2709\n",
      "   macro avg       0.64      0.63      0.63      2709\n",
      "weighted avg       0.64      0.63      0.63      2709\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.97      0.98      0.98       259\n",
      "         0.0       0.98      0.95      0.97       212\n",
      "         1.0       0.95      0.96      0.95       207\n",
      "\n",
      "    accuracy                           0.97       678\n",
      "   macro avg       0.97      0.97      0.97       678\n",
      "weighted avg       0.97      0.97      0.97       678\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       930\n",
      "         0.0       1.00      1.00      1.00       898\n",
      "         1.0       1.00      1.00      1.00       881\n",
      "\n",
      "    accuracy                           1.00      2709\n",
      "   macro avg       1.00      1.00      1.00      2709\n",
      "weighted avg       1.00      1.00      1.00      2709\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.49      0.50      0.50       259\n",
      "         0.0       0.48      0.57      0.52       212\n",
      "         1.0       0.49      0.39      0.44       207\n",
      "\n",
      "    accuracy                           0.49       678\n",
      "   macro avg       0.49      0.49      0.48       678\n",
      "weighted avg       0.49      0.49      0.49       678\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.49      0.58      0.53       930\n",
      "         0.0       0.48      0.53      0.50       898\n",
      "         1.0       0.53      0.37      0.43       881\n",
      "\n",
      "    accuracy                           0.49      2709\n",
      "   macro avg       0.50      0.49      0.49      2709\n",
      "weighted avg       0.50      0.49      0.49      2709\n",
      "\n",
      "\n",
      "--- Classification reports for 'pe_Entry/Exit_ema' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.48      0.67      0.56       244\n",
      "         0.0       0.72      0.51      0.59       213\n",
      "         1.0       0.21      0.17      0.18       181\n",
      "\n",
      "    accuracy                           0.47       638\n",
      "   macro avg       0.47      0.45      0.45       638\n",
      "weighted avg       0.48      0.47      0.46       638\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.44      0.72      0.55       864\n",
      "         0.0       0.73      0.51      0.60       877\n",
      "         1.0       0.27      0.18      0.21       807\n",
      "\n",
      "    accuracy                           0.48      2548\n",
      "   macro avg       0.48      0.47      0.45      2548\n",
      "weighted avg       0.49      0.48      0.46      2548\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.98      0.98      0.98       244\n",
      "         0.0       0.98      0.98      0.98       213\n",
      "         1.0       0.97      0.97      0.97       181\n",
      "\n",
      "    accuracy                           0.97       638\n",
      "   macro avg       0.97      0.97      0.97       638\n",
      "weighted avg       0.97      0.97      0.97       638\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       864\n",
      "         0.0       1.00      1.00      1.00       877\n",
      "         1.0       1.00      1.00      1.00       807\n",
      "\n",
      "    accuracy                           1.00      2548\n",
      "   macro avg       1.00      1.00      1.00      2548\n",
      "weighted avg       1.00      1.00      1.00      2548\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.27      0.28      0.28       244\n",
      "         0.0       0.18      0.21      0.19       213\n",
      "         1.0       0.31      0.22      0.26       181\n",
      "\n",
      "    accuracy                           0.24       638\n",
      "   macro avg       0.25      0.24      0.24       638\n",
      "weighted avg       0.25      0.24      0.24       638\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.18      0.20      0.19       864\n",
      "         0.0       0.19      0.23      0.21       877\n",
      "         1.0       0.36      0.25      0.29       807\n",
      "\n",
      "    accuracy                           0.22      2548\n",
      "   macro avg       0.24      0.22      0.23      2548\n",
      "weighted avg       0.24      0.22      0.23      2548\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define models\n",
    "logistic_regression = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "models = {'Naive Bayes': GaussianNB(),\n",
    "          'Random Forest Classifier': RandomForestClassifier(random_state=42),\n",
    "          'Logistic Regression': logistic_regression}\n",
    "\n",
    "# Create an empty DataFrame to store the classification reports\n",
    "reports_df_test = pd.DataFrame()\n",
    "reports_df_train = pd.DataFrame()\n",
    "\n",
    "# Loop through each y variable\n",
    "for y_var in y_variables:\n",
    "    print(f\"\\n--- Classification reports for '{y_var}' ---\\n\")\n",
    "    \n",
    "    # Drop NaN values from X and y for the current y variable\n",
    "    data_cleaned = nvda_df.dropna(subset=features + [y_var])\n",
    "    X = data_cleaned[features]\n",
    "    y = data_cleaned[y_var]\n",
    "\n",
    "    # Apply SMOTEENN to address class imbalance\n",
    "    smoteenn = SMOTEENN(random_state=42)\n",
    "    X_resampled, y_resampled = smoteenn.fit_resample(X, y)\n",
    "\n",
    "    # Split the resampled data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Scale the features using StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Loop through each model\n",
    "    for model_name, model in models.items():\n",
    "        # Train the model on the training data\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "\n",
    "        # Make predictions on the testing data\n",
    "        y_pred_test = model.predict(X_test_scaled)\n",
    "\n",
    "        # Print label for the model\n",
    "        print(f\"\\n--- {model_name} --- (Testing Data)\")\n",
    "\n",
    "        # Print classification report for testing data\n",
    "        print(classification_report(y_test, y_pred_test))\n",
    "        \n",
    "        # Store classification report for testing data in the DataFrame\n",
    "        report_test = classification_report(y_test, y_pred_test, output_dict=True)\n",
    "        report_df_test = pd.DataFrame(report_test).transpose()\n",
    "        report_df_test['y_variable'] = y_var\n",
    "        report_df_test['model'] = model_name\n",
    "        reports_df_test = pd.concat([reports_df_test, report_df_test])\n",
    "\n",
    "        # Make predictions on the training data\n",
    "        y_pred_train = model.predict(X_train_scaled)\n",
    "\n",
    "        # Print label for the model\n",
    "        print(f\"\\n--- {model_name} --- (Training Data)\")\n",
    "\n",
    "        # Print classification report for training data\n",
    "        print(classification_report(y_train, y_pred_train))\n",
    "\n",
    "        # Store classification report for training data in the DataFrame\n",
    "        report_train = classification_report(y_train, y_pred_train, output_dict=True)\n",
    "        report_df_train = pd.DataFrame(report_train).transpose()\n",
    "        report_df_train['y_variable'] = y_var\n",
    "        report_df_train['model'] = model_name\n",
    "        reports_df_train = pd.concat([reports_df_train, report_df_train])\n",
    "\n",
    "# Export the DataFrames containing classification reports to separate CSV files\n",
    "reports_df_test.to_csv('testing_classification_reports_NVDA_10.csv', index=True)\n",
    "reports_df_train.to_csv('training_classification_reports_NVDA_10.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MMM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) \n",
    "features = ['MMM P/S (LTM)', 'MMM P/FCF (LTM)', 'MMM P/E (LTM)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define y variables\n",
    "y_variables = ['ps_Entry/Exit_sma', 'ps_Entry/Exit_ema', 'pfcf_Entry/Exit_sma',\n",
    "               'pfcf_Entry/Exit_ema', 'pe_Entry/Exit_sma', 'pe_Entry/Exit_ema']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Classification reports for 'ps_Entry/Exit_sma' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.59      0.32      0.42       196\n",
      "         0.0       0.56      0.39      0.46       183\n",
      "         1.0       0.49      0.86      0.62       191\n",
      "\n",
      "    accuracy                           0.52       570\n",
      "   macro avg       0.55      0.52      0.50       570\n",
      "weighted avg       0.55      0.52      0.50       570\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.60      0.36      0.45       743\n",
      "         0.0       0.62      0.44      0.52       749\n",
      "         1.0       0.51      0.85      0.64       786\n",
      "\n",
      "    accuracy                           0.55      2278\n",
      "   macro avg       0.58      0.55      0.53      2278\n",
      "weighted avg       0.58      0.55      0.54      2278\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.96      0.97      0.97       196\n",
      "         0.0       0.97      0.92      0.95       183\n",
      "         1.0       0.96      0.99      0.97       191\n",
      "\n",
      "    accuracy                           0.96       570\n",
      "   macro avg       0.96      0.96      0.96       570\n",
      "weighted avg       0.96      0.96      0.96       570\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       743\n",
      "         0.0       1.00      1.00      1.00       749\n",
      "         1.0       1.00      1.00      1.00       786\n",
      "\n",
      "    accuracy                           1.00      2278\n",
      "   macro avg       1.00      1.00      1.00      2278\n",
      "weighted avg       1.00      1.00      1.00      2278\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.39      0.21      0.28       196\n",
      "         0.0       0.24      0.17      0.20       183\n",
      "         1.0       0.40      0.69      0.51       191\n",
      "\n",
      "    accuracy                           0.36       570\n",
      "   macro avg       0.34      0.36      0.33       570\n",
      "weighted avg       0.34      0.36      0.33       570\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.42      0.26      0.32       743\n",
      "         0.0       0.29      0.21      0.24       749\n",
      "         1.0       0.43      0.71      0.54       786\n",
      "\n",
      "    accuracy                           0.40      2278\n",
      "   macro avg       0.38      0.39      0.37      2278\n",
      "weighted avg       0.38      0.40      0.37      2278\n",
      "\n",
      "\n",
      "--- Classification reports for 'ps_Entry/Exit_ema' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.66      0.47      0.55       189\n",
      "         0.0       0.59      0.68      0.63       201\n",
      "         1.0       0.48      0.54      0.50       190\n",
      "\n",
      "    accuracy                           0.57       580\n",
      "   macro avg       0.58      0.56      0.56       580\n",
      "weighted avg       0.58      0.57      0.56       580\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.61      0.44      0.51       762\n",
      "         0.0       0.57      0.69      0.62       781\n",
      "         1.0       0.47      0.50      0.49       773\n",
      "\n",
      "    accuracy                           0.54      2316\n",
      "   macro avg       0.55      0.54      0.54      2316\n",
      "weighted avg       0.55      0.54      0.54      2316\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.96      1.00      0.98       189\n",
      "         0.0       1.00      0.97      0.98       201\n",
      "         1.0       0.98      0.98      0.98       190\n",
      "\n",
      "    accuracy                           0.98       580\n",
      "   macro avg       0.98      0.98      0.98       580\n",
      "weighted avg       0.98      0.98      0.98       580\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       762\n",
      "         0.0       1.00      1.00      1.00       781\n",
      "         1.0       1.00      1.00      1.00       773\n",
      "\n",
      "    accuracy                           1.00      2316\n",
      "   macro avg       1.00      1.00      1.00      2316\n",
      "weighted avg       1.00      1.00      1.00      2316\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.57      0.64      0.60       189\n",
      "         0.0       0.70      0.78      0.74       201\n",
      "         1.0       0.57      0.44      0.49       190\n",
      "\n",
      "    accuracy                           0.62       580\n",
      "   macro avg       0.62      0.62      0.61       580\n",
      "weighted avg       0.62      0.62      0.62       580\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.54      0.61      0.58       762\n",
      "         0.0       0.73      0.81      0.77       781\n",
      "         1.0       0.54      0.41      0.46       773\n",
      "\n",
      "    accuracy                           0.61      2316\n",
      "   macro avg       0.60      0.61      0.60      2316\n",
      "weighted avg       0.60      0.61      0.60      2316\n",
      "\n",
      "\n",
      "--- Classification reports for 'pfcf_Entry/Exit_sma' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.58      0.84      0.69       186\n",
      "         0.0       0.78      0.35      0.49       186\n",
      "         1.0       0.67      0.74      0.70       182\n",
      "\n",
      "    accuracy                           0.64       554\n",
      "   macro avg       0.68      0.65      0.63       554\n",
      "weighted avg       0.68      0.64      0.63       554\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.59      0.81      0.68       752\n",
      "         0.0       0.72      0.42      0.53       716\n",
      "         1.0       0.65      0.66      0.66       748\n",
      "\n",
      "    accuracy                           0.63      2216\n",
      "   macro avg       0.65      0.63      0.62      2216\n",
      "weighted avg       0.65      0.63      0.62      2216\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.96      0.99      0.98       186\n",
      "         0.0       1.00      0.94      0.97       186\n",
      "         1.0       0.96      0.99      0.98       182\n",
      "\n",
      "    accuracy                           0.97       554\n",
      "   macro avg       0.97      0.97      0.97       554\n",
      "weighted avg       0.97      0.97      0.97       554\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       752\n",
      "         0.0       1.00      1.00      1.00       716\n",
      "         1.0       1.00      1.00      1.00       748\n",
      "\n",
      "    accuracy                           1.00      2216\n",
      "   macro avg       1.00      1.00      1.00      2216\n",
      "weighted avg       1.00      1.00      1.00      2216\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.55      0.74      0.63       186\n",
      "         0.0       0.49      0.22      0.30       186\n",
      "         1.0       0.63      0.78      0.70       182\n",
      "\n",
      "    accuracy                           0.58       554\n",
      "   macro avg       0.56      0.58      0.54       554\n",
      "weighted avg       0.56      0.58      0.54       554\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.58      0.74      0.65       752\n",
      "         0.0       0.48      0.26      0.34       716\n",
      "         1.0       0.65      0.75      0.69       748\n",
      "\n",
      "    accuracy                           0.59      2216\n",
      "   macro avg       0.57      0.58      0.56      2216\n",
      "weighted avg       0.57      0.59      0.56      2216\n",
      "\n",
      "\n",
      "--- Classification reports for 'pfcf_Entry/Exit_ema' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.41      0.59      0.48       159\n",
      "         0.0       0.52      0.43      0.47       152\n",
      "         1.0       0.26      0.19      0.22       171\n",
      "\n",
      "    accuracy                           0.40       482\n",
      "   macro avg       0.40      0.40      0.39       482\n",
      "weighted avg       0.39      0.40      0.39       482\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.38      0.56      0.45       626\n",
      "         0.0       0.58      0.42      0.49       642\n",
      "         1.0       0.31      0.26      0.29       660\n",
      "\n",
      "    accuracy                           0.41      1928\n",
      "   macro avg       0.43      0.41      0.41      1928\n",
      "weighted avg       0.43      0.41      0.41      1928\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.96      0.98      0.97       159\n",
      "         0.0       0.99      0.96      0.97       152\n",
      "         1.0       0.98      0.98      0.98       171\n",
      "\n",
      "    accuracy                           0.98       482\n",
      "   macro avg       0.98      0.97      0.97       482\n",
      "weighted avg       0.98      0.98      0.98       482\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       626\n",
      "         0.0       1.00      1.00      1.00       642\n",
      "         1.0       1.00      1.00      1.00       660\n",
      "\n",
      "    accuracy                           1.00      1928\n",
      "   macro avg       1.00      1.00      1.00      1928\n",
      "weighted avg       1.00      1.00      1.00      1928\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.40      0.39      0.40       159\n",
      "         0.0       0.45      0.43      0.44       152\n",
      "         1.0       0.30      0.32      0.31       171\n",
      "\n",
      "    accuracy                           0.38       482\n",
      "   macro avg       0.38      0.38      0.38       482\n",
      "weighted avg       0.38      0.38      0.38       482\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.38      0.34      0.36       626\n",
      "         0.0       0.51      0.42      0.46       642\n",
      "         1.0       0.33      0.41      0.36       660\n",
      "\n",
      "    accuracy                           0.39      1928\n",
      "   macro avg       0.40      0.39      0.40      1928\n",
      "weighted avg       0.40      0.39      0.40      1928\n",
      "\n",
      "\n",
      "--- Classification reports for 'pe_Entry/Exit_sma' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.61      0.66      0.63       169\n",
      "         0.0       0.66      0.36      0.47       165\n",
      "         1.0       0.59      0.80      0.68       164\n",
      "\n",
      "    accuracy                           0.61       498\n",
      "   macro avg       0.62      0.61      0.59       498\n",
      "weighted avg       0.62      0.61      0.59       498\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.65      0.71      0.68       653\n",
      "         0.0       0.65      0.36      0.46       675\n",
      "         1.0       0.57      0.79      0.67       661\n",
      "\n",
      "    accuracy                           0.62      1989\n",
      "   macro avg       0.63      0.62      0.60      1989\n",
      "weighted avg       0.63      0.62      0.60      1989\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.97      0.99      0.98       169\n",
      "         0.0       0.98      0.98      0.98       165\n",
      "         1.0       0.98      0.96      0.97       164\n",
      "\n",
      "    accuracy                           0.98       498\n",
      "   macro avg       0.98      0.98      0.98       498\n",
      "weighted avg       0.98      0.98      0.98       498\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       653\n",
      "         0.0       1.00      1.00      1.00       675\n",
      "         1.0       1.00      1.00      1.00       661\n",
      "\n",
      "    accuracy                           1.00      1989\n",
      "   macro avg       1.00      1.00      1.00      1989\n",
      "weighted avg       1.00      1.00      1.00      1989\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.74      0.50      0.59       169\n",
      "         0.0       0.52      0.56      0.54       165\n",
      "         1.0       0.57      0.71      0.63       164\n",
      "\n",
      "    accuracy                           0.59       498\n",
      "   macro avg       0.61      0.59      0.59       498\n",
      "weighted avg       0.61      0.59      0.59       498\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.75      0.53      0.62       653\n",
      "         0.0       0.55      0.54      0.54       675\n",
      "         1.0       0.56      0.73      0.64       661\n",
      "\n",
      "    accuracy                           0.60      1989\n",
      "   macro avg       0.62      0.60      0.60      1989\n",
      "weighted avg       0.62      0.60      0.60      1989\n",
      "\n",
      "\n",
      "--- Classification reports for 'pe_Entry/Exit_ema' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.42      0.26      0.32       167\n",
      "         0.0       0.87      0.44      0.58       187\n",
      "         1.0       0.39      0.77      0.52       163\n",
      "\n",
      "    accuracy                           0.49       517\n",
      "   macro avg       0.56      0.49      0.48       517\n",
      "weighted avg       0.58      0.49      0.48       517\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.37      0.21      0.27       665\n",
      "         0.0       0.82      0.42      0.56       683\n",
      "         1.0       0.43      0.79      0.56       716\n",
      "\n",
      "    accuracy                           0.48      2064\n",
      "   macro avg       0.54      0.48      0.46      2064\n",
      "weighted avg       0.54      0.48      0.46      2064\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.97      0.93      0.95       167\n",
      "         0.0       0.96      0.98      0.97       187\n",
      "         1.0       0.96      0.98      0.97       163\n",
      "\n",
      "    accuracy                           0.97       517\n",
      "   macro avg       0.97      0.96      0.96       517\n",
      "weighted avg       0.97      0.97      0.97       517\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       665\n",
      "         0.0       1.00      1.00      1.00       683\n",
      "         1.0       1.00      1.00      1.00       716\n",
      "\n",
      "    accuracy                           1.00      2064\n",
      "   macro avg       1.00      1.00      1.00      2064\n",
      "weighted avg       1.00      1.00      1.00      2064\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.53      0.43      0.47       167\n",
      "         0.0       0.92      0.52      0.67       187\n",
      "         1.0       0.42      0.71      0.52       163\n",
      "\n",
      "    accuracy                           0.55       517\n",
      "   macro avg       0.62      0.55      0.55       517\n",
      "weighted avg       0.64      0.55      0.56       517\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.56      0.48      0.51       665\n",
      "         0.0       0.83      0.53      0.64       683\n",
      "         1.0       0.50      0.74      0.60       716\n",
      "\n",
      "    accuracy                           0.58      2064\n",
      "   macro avg       0.63      0.58      0.58      2064\n",
      "weighted avg       0.63      0.58      0.59      2064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define models\n",
    "logistic_regression = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "models = {'Naive Bayes': GaussianNB(),\n",
    "          'Random Forest Classifier': RandomForestClassifier(random_state=42),\n",
    "          'Logistic Regression': logistic_regression}\n",
    "\n",
    "# Create an empty DataFrame to store the classification reports\n",
    "reports_df_test = pd.DataFrame()\n",
    "reports_df_train = pd.DataFrame()\n",
    "\n",
    "# Loop through each y variable\n",
    "for y_var in y_variables:\n",
    "    print(f\"\\n--- Classification reports for '{y_var}' ---\\n\")\n",
    "    \n",
    "    # Drop NaN values from X and y for the current y variable\n",
    "    data_cleaned = mmm_df.dropna(subset=features + [y_var])\n",
    "    X = data_cleaned[features]\n",
    "    y = data_cleaned[y_var]\n",
    "\n",
    "    # Apply SMOTEENN to address class imbalance\n",
    "    smoteenn = SMOTEENN(random_state=42)\n",
    "    X_resampled, y_resampled = smoteenn.fit_resample(X, y)\n",
    "\n",
    "    # Split the resampled data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Scale the features using StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Loop through each model\n",
    "    for model_name, model in models.items():\n",
    "        # Train the model on the training data\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "\n",
    "        # Make predictions on the testing data\n",
    "        y_pred_test = model.predict(X_test_scaled)\n",
    "\n",
    "        # Print label for the model\n",
    "        print(f\"\\n--- {model_name} --- (Testing Data)\")\n",
    "\n",
    "        # Print classification report for testing data\n",
    "        print(classification_report(y_test, y_pred_test))\n",
    "        \n",
    "        # Store classification report for testing data in the DataFrame\n",
    "        report_test = classification_report(y_test, y_pred_test, output_dict=True)\n",
    "        report_df_test = pd.DataFrame(report_test).transpose()\n",
    "        report_df_test['y_variable'] = y_var\n",
    "        report_df_test['model'] = model_name\n",
    "        reports_df_test = pd.concat([reports_df_test, report_df_test])\n",
    "\n",
    "        # Make predictions on the training data\n",
    "        y_pred_train = model.predict(X_train_scaled)\n",
    "\n",
    "        # Print label for the model\n",
    "        print(f\"\\n--- {model_name} --- (Training Data)\")\n",
    "\n",
    "        # Print classification report for training data\n",
    "        print(classification_report(y_train, y_pred_train))\n",
    "\n",
    "        # Store classification report for training data in the DataFrame\n",
    "        report_train = classification_report(y_train, y_pred_train, output_dict=True)\n",
    "        report_df_train = pd.DataFrame(report_train).transpose()\n",
    "        report_df_train['y_variable'] = y_var\n",
    "        report_df_train['model'] = model_name\n",
    "        reports_df_train = pd.concat([reports_df_train, report_df_train])\n",
    "\n",
    "# Export the DataFrames containing classification reports to separate CSV files\n",
    "reports_df_test.to_csv('testing_classification_reports_MMM_10.csv', index=True)\n",
    "reports_df_train.to_csv('training_classification_reports_MMM_10.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) \n",
    "features = ['PG P/S (LTM)', 'PG P/FCF (LTM)', 'PG P/E (LTM)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define y variables\n",
    "y_variables = ['ps_Entry/Exit_sma', 'ps_Entry/Exit_ema', 'pfcf_Entry/Exit_sma',\n",
    "               'pfcf_Entry/Exit_ema', 'pe_Entry/Exit_sma', 'pe_Entry/Exit_ema']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Classification reports for 'ps_Entry/Exit_sma' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.50      0.63      0.56       174\n",
      "         0.0       0.71      0.47      0.57       189\n",
      "         1.0       0.38      0.42      0.40       163\n",
      "\n",
      "    accuracy                           0.51       526\n",
      "   macro avg       0.53      0.51      0.51       526\n",
      "weighted avg       0.54      0.51      0.51       526\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.51      0.65      0.57       671\n",
      "         0.0       0.75      0.50      0.60       768\n",
      "         1.0       0.45      0.50      0.48       663\n",
      "\n",
      "    accuracy                           0.55      2102\n",
      "   macro avg       0.57      0.55      0.55      2102\n",
      "weighted avg       0.58      0.55      0.55      2102\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.96      0.99      0.97       174\n",
      "         0.0       0.99      0.97      0.98       189\n",
      "         1.0       0.99      0.98      0.98       163\n",
      "\n",
      "    accuracy                           0.98       526\n",
      "   macro avg       0.98      0.98      0.98       526\n",
      "weighted avg       0.98      0.98      0.98       526\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       671\n",
      "         0.0       1.00      1.00      1.00       768\n",
      "         1.0       1.00      1.00      1.00       663\n",
      "\n",
      "    accuracy                           1.00      2102\n",
      "   macro avg       1.00      1.00      1.00      2102\n",
      "weighted avg       1.00      1.00      1.00      2102\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.48      0.62      0.54       174\n",
      "         0.0       0.55      0.63      0.59       189\n",
      "         1.0       0.29      0.15      0.20       163\n",
      "\n",
      "    accuracy                           0.48       526\n",
      "   macro avg       0.44      0.47      0.44       526\n",
      "weighted avg       0.45      0.48      0.45       526\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.47      0.64      0.54       671\n",
      "         0.0       0.51      0.57      0.54       768\n",
      "         1.0       0.34      0.17      0.23       663\n",
      "\n",
      "    accuracy                           0.47      2102\n",
      "   macro avg       0.44      0.46      0.44      2102\n",
      "weighted avg       0.44      0.47      0.44      2102\n",
      "\n",
      "\n",
      "--- Classification reports for 'ps_Entry/Exit_ema' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.43      0.67      0.52       201\n",
      "         0.0       0.78      0.22      0.34       203\n",
      "         1.0       0.40      0.45      0.42       211\n",
      "\n",
      "    accuracy                           0.45       615\n",
      "   macro avg       0.53      0.45      0.43       615\n",
      "weighted avg       0.53      0.45      0.43       615\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.41      0.65      0.50       759\n",
      "         0.0       0.83      0.23      0.36       860\n",
      "         1.0       0.36      0.44      0.40       837\n",
      "\n",
      "    accuracy                           0.43      2456\n",
      "   macro avg       0.54      0.44      0.42      2456\n",
      "weighted avg       0.54      0.43      0.42      2456\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.99      0.97      0.98       201\n",
      "         0.0       0.99      0.98      0.98       203\n",
      "         1.0       0.96      1.00      0.98       211\n",
      "\n",
      "    accuracy                           0.98       615\n",
      "   macro avg       0.98      0.98      0.98       615\n",
      "weighted avg       0.98      0.98      0.98       615\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       759\n",
      "         0.0       1.00      1.00      1.00       860\n",
      "         1.0       1.00      1.00      1.00       837\n",
      "\n",
      "    accuracy                           1.00      2456\n",
      "   macro avg       1.00      1.00      1.00      2456\n",
      "weighted avg       1.00      1.00      1.00      2456\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.42      0.47      0.44       201\n",
      "         0.0       0.47      0.45      0.46       203\n",
      "         1.0       0.32      0.29      0.30       211\n",
      "\n",
      "    accuracy                           0.40       615\n",
      "   macro avg       0.40      0.40      0.40       615\n",
      "weighted avg       0.40      0.40      0.40       615\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.42      0.49      0.45       759\n",
      "         0.0       0.51      0.48      0.50       860\n",
      "         1.0       0.34      0.30      0.32       837\n",
      "\n",
      "    accuracy                           0.42      2456\n",
      "   macro avg       0.42      0.43      0.42      2456\n",
      "weighted avg       0.42      0.42      0.42      2456\n",
      "\n",
      "\n",
      "--- Classification reports for 'pfcf_Entry/Exit_sma' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.51      0.39      0.44       211\n",
      "         0.0       0.67      0.54      0.60       210\n",
      "         1.0       0.48      0.69      0.56       199\n",
      "\n",
      "    accuracy                           0.54       620\n",
      "   macro avg       0.55      0.54      0.54       620\n",
      "weighted avg       0.55      0.54      0.54       620\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.47      0.40      0.43       761\n",
      "         0.0       0.72      0.57      0.64       918\n",
      "         1.0       0.47      0.65      0.55       801\n",
      "\n",
      "    accuracy                           0.54      2480\n",
      "   macro avg       0.55      0.54      0.54      2480\n",
      "weighted avg       0.56      0.54      0.54      2480\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.98      0.98      0.98       211\n",
      "         0.0       0.99      0.97      0.98       210\n",
      "         1.0       0.98      0.99      0.99       199\n",
      "\n",
      "    accuracy                           0.98       620\n",
      "   macro avg       0.98      0.98      0.98       620\n",
      "weighted avg       0.98      0.98      0.98       620\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       761\n",
      "         0.0       1.00      1.00      1.00       918\n",
      "         1.0       1.00      1.00      1.00       801\n",
      "\n",
      "    accuracy                           1.00      2480\n",
      "   macro avg       1.00      1.00      1.00      2480\n",
      "weighted avg       1.00      1.00      1.00      2480\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.50      0.39      0.44       211\n",
      "         0.0       0.33      0.52      0.40       210\n",
      "         1.0       0.43      0.25      0.32       199\n",
      "\n",
      "    accuracy                           0.39       620\n",
      "   macro avg       0.42      0.39      0.39       620\n",
      "weighted avg       0.42      0.39      0.39       620\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.43      0.39      0.41       761\n",
      "         0.0       0.35      0.49      0.41       918\n",
      "         1.0       0.41      0.25      0.31       801\n",
      "\n",
      "    accuracy                           0.38      2480\n",
      "   macro avg       0.40      0.38      0.38      2480\n",
      "weighted avg       0.39      0.38      0.38      2480\n",
      "\n",
      "\n",
      "--- Classification reports for 'pfcf_Entry/Exit_ema' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.49      0.58      0.53       182\n",
      "         0.0       0.47      0.49      0.48       206\n",
      "         1.0       0.49      0.38      0.43       185\n",
      "\n",
      "    accuracy                           0.48       573\n",
      "   macro avg       0.48      0.48      0.48       573\n",
      "weighted avg       0.48      0.48      0.48       573\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.50      0.61      0.55       714\n",
      "         0.0       0.48      0.47      0.48       854\n",
      "         1.0       0.46      0.37      0.41       724\n",
      "\n",
      "    accuracy                           0.48      2292\n",
      "   macro avg       0.48      0.48      0.48      2292\n",
      "weighted avg       0.48      0.48      0.48      2292\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.97      0.96      0.96       182\n",
      "         0.0       0.98      0.99      0.98       206\n",
      "         1.0       0.98      0.98      0.98       185\n",
      "\n",
      "    accuracy                           0.98       573\n",
      "   macro avg       0.98      0.98      0.98       573\n",
      "weighted avg       0.98      0.98      0.98       573\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       714\n",
      "         0.0       1.00      1.00      1.00       854\n",
      "         1.0       1.00      1.00      1.00       724\n",
      "\n",
      "    accuracy                           1.00      2292\n",
      "   macro avg       1.00      1.00      1.00      2292\n",
      "weighted avg       1.00      1.00      1.00      2292\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.54      0.51      0.52       182\n",
      "         0.0       0.47      0.78      0.59       206\n",
      "         1.0       0.46      0.16      0.23       185\n",
      "\n",
      "    accuracy                           0.49       573\n",
      "   macro avg       0.49      0.48      0.45       573\n",
      "weighted avg       0.49      0.49      0.45       573\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.52      0.52      0.52       714\n",
      "         0.0       0.47      0.73      0.57       854\n",
      "         1.0       0.40      0.14      0.21       724\n",
      "\n",
      "    accuracy                           0.48      2292\n",
      "   macro avg       0.46      0.46      0.43      2292\n",
      "weighted avg       0.46      0.48      0.44      2292\n",
      "\n",
      "\n",
      "--- Classification reports for 'pe_Entry/Exit_sma' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.51      0.54      0.52       209\n",
      "         0.0       0.84      0.52      0.64       208\n",
      "         1.0       0.47      0.64      0.54       184\n",
      "\n",
      "    accuracy                           0.56       601\n",
      "   macro avg       0.61      0.57      0.57       601\n",
      "weighted avg       0.61      0.56      0.57       601\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.42      0.49      0.45       724\n",
      "         0.0       0.81      0.49      0.61       873\n",
      "         1.0       0.47      0.59      0.52       803\n",
      "\n",
      "    accuracy                           0.52      2400\n",
      "   macro avg       0.56      0.52      0.53      2400\n",
      "weighted avg       0.58      0.52      0.53      2400\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.96      0.95      0.95       209\n",
      "         0.0       0.99      0.96      0.98       208\n",
      "         1.0       0.93      0.99      0.96       184\n",
      "\n",
      "    accuracy                           0.96       601\n",
      "   macro avg       0.96      0.96      0.96       601\n",
      "weighted avg       0.96      0.96      0.96       601\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       724\n",
      "         0.0       1.00      1.00      1.00       873\n",
      "         1.0       1.00      1.00      1.00       803\n",
      "\n",
      "    accuracy                           1.00      2400\n",
      "   macro avg       1.00      1.00      1.00      2400\n",
      "weighted avg       1.00      1.00      1.00      2400\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.51      0.40      0.45       209\n",
      "         0.0       0.59      0.50      0.54       208\n",
      "         1.0       0.48      0.68      0.57       184\n",
      "\n",
      "    accuracy                           0.52       601\n",
      "   macro avg       0.53      0.53      0.52       601\n",
      "weighted avg       0.53      0.52      0.52       601\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.42      0.36      0.39       724\n",
      "         0.0       0.58      0.53      0.55       873\n",
      "         1.0       0.51      0.62      0.56       803\n",
      "\n",
      "    accuracy                           0.51      2400\n",
      "   macro avg       0.50      0.50      0.50      2400\n",
      "weighted avg       0.51      0.51      0.51      2400\n",
      "\n",
      "\n",
      "--- Classification reports for 'pe_Entry/Exit_ema' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.39      0.59      0.47       216\n",
      "         0.0       0.75      0.22      0.34       210\n",
      "         1.0       0.39      0.46      0.42       200\n",
      "\n",
      "    accuracy                           0.43       626\n",
      "   macro avg       0.51      0.43      0.41       626\n",
      "weighted avg       0.51      0.43      0.41       626\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.37      0.60      0.46       777\n",
      "         0.0       0.72      0.21      0.33       894\n",
      "         1.0       0.46      0.54      0.50       833\n",
      "\n",
      "    accuracy                           0.44      2504\n",
      "   macro avg       0.52      0.45      0.43      2504\n",
      "weighted avg       0.52      0.44      0.42      2504\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.96      0.98      0.97       216\n",
      "         0.0       0.98      0.98      0.98       210\n",
      "         1.0       0.98      0.96      0.97       200\n",
      "\n",
      "    accuracy                           0.97       626\n",
      "   macro avg       0.97      0.97      0.97       626\n",
      "weighted avg       0.97      0.97      0.97       626\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       777\n",
      "         0.0       1.00      1.00      1.00       894\n",
      "         1.0       1.00      1.00      1.00       833\n",
      "\n",
      "    accuracy                           1.00      2504\n",
      "   macro avg       1.00      1.00      1.00      2504\n",
      "weighted avg       1.00      1.00      1.00      2504\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.55      0.31      0.39       216\n",
      "         0.0       0.44      0.55      0.49       210\n",
      "         1.0       0.41      0.50      0.45       200\n",
      "\n",
      "    accuracy                           0.45       626\n",
      "   macro avg       0.47      0.45      0.44       626\n",
      "weighted avg       0.47      0.45      0.44       626\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.48      0.33      0.39       777\n",
      "         0.0       0.50      0.58      0.54       894\n",
      "         1.0       0.44      0.49      0.47       833\n",
      "\n",
      "    accuracy                           0.47      2504\n",
      "   macro avg       0.47      0.47      0.47      2504\n",
      "weighted avg       0.47      0.47      0.47      2504\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define models\n",
    "logistic_regression = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "models = {'Naive Bayes': GaussianNB(),\n",
    "          'Random Forest Classifier': RandomForestClassifier(random_state=42),\n",
    "          'Logistic Regression': logistic_regression}\n",
    "\n",
    "# Create an empty DataFrame to store the classification reports\n",
    "reports_df_test = pd.DataFrame()\n",
    "reports_df_train = pd.DataFrame()\n",
    "\n",
    "# Loop through each y variable\n",
    "for y_var in y_variables:\n",
    "    print(f\"\\n--- Classification reports for '{y_var}' ---\\n\")\n",
    "    \n",
    "    # Drop NaN values from X and y for the current y variable\n",
    "    data_cleaned = pg_df.dropna(subset=features + [y_var])\n",
    "    X = data_cleaned[features]\n",
    "    y = data_cleaned[y_var]\n",
    "\n",
    "    # Apply SMOTEENN to address class imbalance\n",
    "    smoteenn = SMOTEENN(random_state=42)\n",
    "    X_resampled, y_resampled = smoteenn.fit_resample(X, y)\n",
    "\n",
    "    # Split the resampled data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Scale the features using StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Loop through each model\n",
    "    for model_name, model in models.items():\n",
    "        # Train the model on the training data\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "\n",
    "        # Make predictions on the testing data\n",
    "        y_pred_test = model.predict(X_test_scaled)\n",
    "\n",
    "        # Print label for the model\n",
    "        print(f\"\\n--- {model_name} --- (Testing Data)\")\n",
    "\n",
    "        # Print classification report for testing data\n",
    "        print(classification_report(y_test, y_pred_test))\n",
    "        \n",
    "        # Store classification report for testing data in the DataFrame\n",
    "        report_test = classification_report(y_test, y_pred_test, output_dict=True)\n",
    "        report_df_test = pd.DataFrame(report_test).transpose()\n",
    "        report_df_test['y_variable'] = y_var\n",
    "        report_df_test['model'] = model_name\n",
    "        reports_df_test = pd.concat([reports_df_test, report_df_test])\n",
    "\n",
    "        # Make predictions on the training data\n",
    "        y_pred_train = model.predict(X_train_scaled)\n",
    "\n",
    "        # Print label for the model\n",
    "        print(f\"\\n--- {model_name} --- (Training Data)\")\n",
    "\n",
    "        # Print classification report for training data\n",
    "        print(classification_report(y_train, y_pred_train))\n",
    "\n",
    "        # Store classification report for training data in the DataFrame\n",
    "        report_train = classification_report(y_train, y_pred_train, output_dict=True)\n",
    "        report_df_train = pd.DataFrame(report_train).transpose()\n",
    "        report_df_train['y_variable'] = y_var\n",
    "        report_df_train['model'] = model_name\n",
    "        reports_df_train = pd.concat([reports_df_train, report_df_train])\n",
    "\n",
    "# Export the DataFrames containing classification reports to separate CSV files\n",
    "reports_df_test.to_csv('testing_classification_reports_PG_10.csv', index=True)\n",
    "reports_df_train.to_csv('training_classification_reports_PG_10.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
