{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "from pathlib import Path\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_rows', None)  # To show all rows\n",
    "pd.set_option('display.max_columns', None)  # To show all columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GOOGLE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the CSV files that contain SMA, EMA, and BB/RSI inidcators based on ratio data\n",
    "googl_df = pd.read_csv(\"googl_signals.csv\", infer_datetime_format=True, index_col=\"Date\", parse_dates=True)\n",
    "nvda_df = pd.read_csv(\"nvda_signals.csv\", infer_datetime_format=True, index_col=\"Date\", parse_dates=True)\n",
    "mmm_df = pd.read_csv(\"mmm_signals.csv\", infer_datetime_format=True, index_col=\"Date\", parse_dates=True)\n",
    "pg_df = pd.read_csv(\"pg_signals.csv\", infer_datetime_format=True, index_col=\"Date\", parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for machine learning, scaling, resampling and classification reports \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.combine import SMOTEENN\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) \n",
    "features = ['GOOGL P/S (LTM)', 'GOOGL P/FCF (LTM)', 'GOOGL P/E (LTM)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define y variables\n",
    "y_variables = ['ps_Entry/Exit_sma', 'ps_Entry/Exit_ema', 'pfcf_Entry/Exit_sma',\n",
    "               'pfcf_Entry/Exit_ema', 'pe_Entry/Exit_sma', 'pe_Entry/Exit_ema']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Classification reports for 'ps_Entry/Exit_sma' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.34      0.10      0.15       242\n",
      "         0.0       0.52      0.48      0.50       221\n",
      "         1.0       0.39      0.75      0.51       205\n",
      "\n",
      "    accuracy                           0.42       668\n",
      "   macro avg       0.42      0.44      0.39       668\n",
      "weighted avg       0.41      0.42      0.37       668\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.33      0.10      0.16       863\n",
      "         0.0       0.46      0.44      0.45       887\n",
      "         1.0       0.41      0.70      0.52       921\n",
      "\n",
      "    accuracy                           0.42      2671\n",
      "   macro avg       0.40      0.41      0.37      2671\n",
      "weighted avg       0.40      0.42      0.38      2671\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.97      0.98      0.97       242\n",
      "         0.0       1.00      0.96      0.98       221\n",
      "         1.0       0.97      1.00      0.98       205\n",
      "\n",
      "    accuracy                           0.98       668\n",
      "   macro avg       0.98      0.98      0.98       668\n",
      "weighted avg       0.98      0.98      0.98       668\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       863\n",
      "         0.0       1.00      1.00      1.00       887\n",
      "         1.0       1.00      1.00      1.00       921\n",
      "\n",
      "    accuracy                           1.00      2671\n",
      "   macro avg       1.00      1.00      1.00      2671\n",
      "weighted avg       1.00      1.00      1.00      2671\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.62      0.15      0.25       242\n",
      "         0.0       0.41      0.52      0.46       221\n",
      "         1.0       0.37      0.60      0.46       205\n",
      "\n",
      "    accuracy                           0.41       668\n",
      "   macro avg       0.47      0.42      0.39       668\n",
      "weighted avg       0.47      0.41      0.38       668\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.52      0.11      0.18       863\n",
      "         0.0       0.41      0.56      0.47       887\n",
      "         1.0       0.41      0.58      0.48       921\n",
      "\n",
      "    accuracy                           0.42      2671\n",
      "   macro avg       0.45      0.41      0.38      2671\n",
      "weighted avg       0.45      0.42      0.38      2671\n",
      "\n",
      "\n",
      "--- Classification reports for 'ps_Entry/Exit_ema' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.40      0.31      0.35       255\n",
      "         0.0       0.53      0.40      0.46       202\n",
      "         1.0       0.37      0.56      0.45       218\n",
      "\n",
      "    accuracy                           0.42       675\n",
      "   macro avg       0.43      0.42      0.42       675\n",
      "weighted avg       0.43      0.42      0.41       675\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.37      0.34      0.35       916\n",
      "         0.0       0.51      0.41      0.46       889\n",
      "         1.0       0.38      0.49      0.43       895\n",
      "\n",
      "    accuracy                           0.41      2700\n",
      "   macro avg       0.42      0.42      0.41      2700\n",
      "weighted avg       0.42      0.41      0.41      2700\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.98      1.00      0.99       255\n",
      "         0.0       0.99      0.98      0.99       202\n",
      "         1.0       0.99      0.98      0.98       218\n",
      "\n",
      "    accuracy                           0.99       675\n",
      "   macro avg       0.99      0.99      0.99       675\n",
      "weighted avg       0.99      0.99      0.99       675\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       916\n",
      "         0.0       1.00      1.00      1.00       889\n",
      "         1.0       1.00      1.00      1.00       895\n",
      "\n",
      "    accuracy                           1.00      2700\n",
      "   macro avg       1.00      1.00      1.00      2700\n",
      "weighted avg       1.00      1.00      1.00      2700\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.37      0.38      0.38       255\n",
      "         0.0       0.36      0.23      0.28       202\n",
      "         1.0       0.27      0.35      0.31       218\n",
      "\n",
      "    accuracy                           0.33       675\n",
      "   macro avg       0.33      0.32      0.32       675\n",
      "weighted avg       0.34      0.33      0.33       675\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.36      0.43      0.39       916\n",
      "         0.0       0.37      0.24      0.29       889\n",
      "         1.0       0.30      0.34      0.32       895\n",
      "\n",
      "    accuracy                           0.34      2700\n",
      "   macro avg       0.34      0.34      0.33      2700\n",
      "weighted avg       0.34      0.34      0.33      2700\n",
      "\n",
      "\n",
      "--- Classification reports for 'pfcf_Entry/Exit_sma' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.55      0.26      0.35       249\n",
      "         0.0       0.44      0.40      0.42       205\n",
      "         1.0       0.38      0.67      0.49       201\n",
      "\n",
      "    accuracy                           0.43       655\n",
      "   macro avg       0.46      0.44      0.42       655\n",
      "weighted avg       0.47      0.43      0.42       655\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.46      0.26      0.33       841\n",
      "         0.0       0.47      0.38      0.42       883\n",
      "         1.0       0.43      0.69      0.53       892\n",
      "\n",
      "    accuracy                           0.45      2616\n",
      "   macro avg       0.45      0.44      0.43      2616\n",
      "weighted avg       0.45      0.45      0.43      2616\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.98      0.98      0.98       249\n",
      "         0.0       0.97      0.96      0.97       205\n",
      "         1.0       0.98      0.99      0.99       201\n",
      "\n",
      "    accuracy                           0.98       655\n",
      "   macro avg       0.98      0.98      0.98       655\n",
      "weighted avg       0.98      0.98      0.98       655\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       841\n",
      "         0.0       1.00      1.00      1.00       883\n",
      "         1.0       1.00      1.00      1.00       892\n",
      "\n",
      "    accuracy                           1.00      2616\n",
      "   macro avg       1.00      1.00      1.00      2616\n",
      "weighted avg       1.00      1.00      1.00      2616\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.49      0.22      0.31       249\n",
      "         0.0       0.47      0.57      0.52       205\n",
      "         1.0       0.38      0.55      0.45       201\n",
      "\n",
      "    accuracy                           0.43       655\n",
      "   macro avg       0.45      0.45      0.42       655\n",
      "weighted avg       0.45      0.43      0.42       655\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.32      0.17      0.23       841\n",
      "         0.0       0.47      0.56      0.51       883\n",
      "         1.0       0.44      0.55      0.49       892\n",
      "\n",
      "    accuracy                           0.43      2616\n",
      "   macro avg       0.41      0.43      0.41      2616\n",
      "weighted avg       0.41      0.43      0.41      2616\n",
      "\n",
      "\n",
      "--- Classification reports for 'pfcf_Entry/Exit_ema' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.61      0.42      0.50       250\n",
      "         0.0       0.35      0.49      0.41       184\n",
      "         1.0       0.60      0.61      0.61       209\n",
      "\n",
      "    accuracy                           0.50       643\n",
      "   macro avg       0.52      0.51      0.51       643\n",
      "weighted avg       0.53      0.50      0.51       643\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.60      0.43      0.50       873\n",
      "         0.0       0.42      0.52      0.47       856\n",
      "         1.0       0.58      0.63      0.61       843\n",
      "\n",
      "    accuracy                           0.52      2572\n",
      "   macro avg       0.54      0.52      0.52      2572\n",
      "weighted avg       0.54      0.52      0.52      2572\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      0.98      0.99       250\n",
      "         0.0       0.98      0.99      0.99       184\n",
      "         1.0       0.98      0.99      0.99       209\n",
      "\n",
      "    accuracy                           0.99       643\n",
      "   macro avg       0.99      0.99      0.99       643\n",
      "weighted avg       0.99      0.99      0.99       643\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       873\n",
      "         0.0       1.00      1.00      1.00       856\n",
      "         1.0       1.00      1.00      1.00       843\n",
      "\n",
      "    accuracy                           1.00      2572\n",
      "   macro avg       1.00      1.00      1.00      2572\n",
      "weighted avg       1.00      1.00      1.00      2572\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.48      0.64      0.55       250\n",
      "         0.0       0.43      0.64      0.51       184\n",
      "         1.0       0.56      0.11      0.18       209\n",
      "\n",
      "    accuracy                           0.47       643\n",
      "   macro avg       0.49      0.46      0.41       643\n",
      "weighted avg       0.49      0.47      0.42       643\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.43      0.63      0.51       873\n",
      "         0.0       0.48      0.64      0.55       856\n",
      "         1.0       0.55      0.10      0.17       843\n",
      "\n",
      "    accuracy                           0.46      2572\n",
      "   macro avg       0.49      0.46      0.41      2572\n",
      "weighted avg       0.49      0.46      0.41      2572\n",
      "\n",
      "\n",
      "--- Classification reports for 'pe_Entry/Exit_sma' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.33      0.13      0.19       216\n",
      "         0.0       0.49      0.42      0.45       208\n",
      "         1.0       0.44      0.79      0.57       206\n",
      "\n",
      "    accuracy                           0.44       630\n",
      "   macro avg       0.42      0.45      0.40       630\n",
      "weighted avg       0.42      0.44      0.40       630\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.37      0.14      0.21       778\n",
      "         0.0       0.50      0.40      0.44       875\n",
      "         1.0       0.48      0.84      0.61       866\n",
      "\n",
      "    accuracy                           0.47      2519\n",
      "   macro avg       0.45      0.46      0.42      2519\n",
      "weighted avg       0.45      0.47      0.43      2519\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.98      0.98      0.98       216\n",
      "         0.0       0.98      0.98      0.98       208\n",
      "         1.0       0.99      0.99      0.99       206\n",
      "\n",
      "    accuracy                           0.98       630\n",
      "   macro avg       0.98      0.98      0.98       630\n",
      "weighted avg       0.98      0.98      0.98       630\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       778\n",
      "         0.0       1.00      1.00      1.00       875\n",
      "         1.0       1.00      1.00      1.00       866\n",
      "\n",
      "    accuracy                           1.00      2519\n",
      "   macro avg       1.00      1.00      1.00      2519\n",
      "weighted avg       1.00      1.00      1.00      2519\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.45      0.39      0.42       216\n",
      "         0.0       0.38      0.40      0.39       208\n",
      "         1.0       0.49      0.53      0.51       206\n",
      "\n",
      "    accuracy                           0.44       630\n",
      "   macro avg       0.44      0.44      0.44       630\n",
      "weighted avg       0.44      0.44      0.44       630\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.40      0.41      0.40       778\n",
      "         0.0       0.40      0.38      0.39       875\n",
      "         1.0       0.49      0.50      0.49       866\n",
      "\n",
      "    accuracy                           0.43      2519\n",
      "   macro avg       0.43      0.43      0.43      2519\n",
      "weighted avg       0.43      0.43      0.43      2519\n",
      "\n",
      "\n",
      "--- Classification reports for 'pe_Entry/Exit_ema' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.55      0.71      0.62       241\n",
      "         0.0       0.55      0.40      0.46       202\n",
      "         1.0       0.54      0.50      0.52       208\n",
      "\n",
      "    accuracy                           0.55       651\n",
      "   macro avg       0.55      0.54      0.53       651\n",
      "weighted avg       0.55      0.55      0.54       651\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.44      0.66      0.53       820\n",
      "         0.0       0.61      0.41      0.49       888\n",
      "         1.0       0.51      0.45      0.48       895\n",
      "\n",
      "    accuracy                           0.50      2603\n",
      "   macro avg       0.52      0.51      0.50      2603\n",
      "weighted avg       0.52      0.50      0.50      2603\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      0.98      0.99       241\n",
      "         0.0       0.98      0.99      0.98       202\n",
      "         1.0       0.97      1.00      0.98       208\n",
      "\n",
      "    accuracy                           0.98       651\n",
      "   macro avg       0.98      0.99      0.98       651\n",
      "weighted avg       0.98      0.98      0.98       651\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       820\n",
      "         0.0       1.00      1.00      1.00       888\n",
      "         1.0       1.00      1.00      1.00       895\n",
      "\n",
      "    accuracy                           1.00      2603\n",
      "   macro avg       1.00      1.00      1.00      2603\n",
      "weighted avg       1.00      1.00      1.00      2603\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.43      0.44      0.44       241\n",
      "         0.0       0.33      0.33      0.33       202\n",
      "         1.0       0.44      0.43      0.44       208\n",
      "\n",
      "    accuracy                           0.40       651\n",
      "   macro avg       0.40      0.40      0.40       651\n",
      "weighted avg       0.40      0.40      0.40       651\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.35      0.40      0.38       820\n",
      "         0.0       0.33      0.31      0.32       888\n",
      "         1.0       0.41      0.37      0.39       895\n",
      "\n",
      "    accuracy                           0.36      2603\n",
      "   macro avg       0.36      0.36      0.36      2603\n",
      "weighted avg       0.36      0.36      0.36      2603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define models\n",
    "logistic_regression = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "models = {'Naive Bayes': GaussianNB(),\n",
    "          'Random Forest Classifier': RandomForestClassifier(random_state=42),\n",
    "          'Logistic Regression': logistic_regression}\n",
    "\n",
    "# Create an empty DataFrame to store the classification reports\n",
    "reports_df_test = pd.DataFrame()\n",
    "reports_df_train = pd.DataFrame()\n",
    "\n",
    "# Loop through each y variable\n",
    "for y_var in y_variables:\n",
    "    print(f\"\\n--- Classification reports for '{y_var}' ---\\n\")\n",
    "    \n",
    "    # Drop NaN values from X and y for the current y variable\n",
    "    data_cleaned = googl_df.dropna(subset=features + [y_var])\n",
    "    X = data_cleaned[features]\n",
    "    y = data_cleaned[y_var]\n",
    "\n",
    "    # Apply SMOTEENN to address class imbalance\n",
    "    smoteenn = SMOTEENN(random_state=42)\n",
    "    X_resampled, y_resampled = smoteenn.fit_resample(X, y)\n",
    "\n",
    "    # Split the resampled data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Scale the features using StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Loop through each model\n",
    "    for model_name, model in models.items():\n",
    "        # Train the model on the training data\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "\n",
    "        # Make predictions on the testing data\n",
    "        y_pred_test = model.predict(X_test_scaled)\n",
    "\n",
    "        # Print label for the model\n",
    "        print(f\"\\n--- {model_name} --- (Testing Data)\")\n",
    "\n",
    "        # Print classification report for testing data\n",
    "        print(classification_report(y_test, y_pred_test))\n",
    "        \n",
    "        # Store classification report for testing data in the DataFrame\n",
    "        report_test = classification_report(y_test, y_pred_test, output_dict=True)\n",
    "        report_df_test = pd.DataFrame(report_test).transpose()\n",
    "        report_df_test['y_variable'] = y_var\n",
    "        report_df_test['model'] = model_name\n",
    "        reports_df_test = pd.concat([reports_df_test, report_df_test])\n",
    "\n",
    "        # Make predictions on the training data\n",
    "        y_pred_train = model.predict(X_train_scaled)\n",
    "\n",
    "        # Print label for the model\n",
    "        print(f\"\\n--- {model_name} --- (Training Data)\")\n",
    "\n",
    "        # Print classification report for training data\n",
    "        print(classification_report(y_train, y_pred_train))\n",
    "\n",
    "        # Store classification report for training data in the DataFrame\n",
    "        report_train = classification_report(y_train, y_pred_train, output_dict=True)\n",
    "        report_df_train = pd.DataFrame(report_train).transpose()\n",
    "        report_df_train['y_variable'] = y_var\n",
    "        report_df_train['model'] = model_name\n",
    "        reports_df_train = pd.concat([reports_df_train, report_df_train])\n",
    "\n",
    "# Export the DataFrames containing classification reports to separate CSV files\n",
    "reports_df_test.to_csv('testing_classification_reports_GOOGLE_10.csv', index=True)\n",
    "reports_df_train.to_csv('training_classification_reports_GOOGLE_10.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NVDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X)\n",
    "features = ['NVDA P/S (LTM)', 'NVDA P/FCF (LTM)', 'NVDA P/E (LTM)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define y variables\n",
    "y_variables = ['ps_Entry/Exit_sma', 'ps_Entry/Exit_ema', 'pfcf_Entry/Exit_sma',\n",
    "               'pfcf_Entry/Exit_ema', 'pe_Entry/Exit_sma', 'pe_Entry/Exit_ema']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Classification reports for 'ps_Entry/Exit_sma' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.49      0.84      0.62       238\n",
      "         0.0       0.52      0.39      0.45       201\n",
      "         1.0       0.11      0.04      0.06       193\n",
      "\n",
      "    accuracy                           0.45       632\n",
      "   macro avg       0.37      0.42      0.37       632\n",
      "weighted avg       0.38      0.45      0.39       632\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.44      0.83      0.57       851\n",
      "         0.0       0.52      0.38      0.44       852\n",
      "         1.0       0.16      0.06      0.09       824\n",
      "\n",
      "    accuracy                           0.43      2527\n",
      "   macro avg       0.37      0.42      0.37      2527\n",
      "weighted avg       0.38      0.43      0.37      2527\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.97      0.98      0.98       238\n",
      "         0.0       0.99      0.96      0.97       201\n",
      "         1.0       0.97      0.99      0.98       193\n",
      "\n",
      "    accuracy                           0.98       632\n",
      "   macro avg       0.98      0.98      0.98       632\n",
      "weighted avg       0.98      0.98      0.98       632\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       851\n",
      "         0.0       1.00      1.00      1.00       852\n",
      "         1.0       1.00      1.00      1.00       824\n",
      "\n",
      "    accuracy                           1.00      2527\n",
      "   macro avg       1.00      1.00      1.00      2527\n",
      "weighted avg       1.00      1.00      1.00      2527\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.35      0.41      0.38       238\n",
      "         0.0       0.24      0.30      0.27       201\n",
      "         1.0       0.12      0.06      0.08       193\n",
      "\n",
      "    accuracy                           0.27       632\n",
      "   macro avg       0.24      0.26      0.24       632\n",
      "weighted avg       0.24      0.27      0.25       632\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.30      0.38      0.33       851\n",
      "         0.0       0.26      0.31      0.28       852\n",
      "         1.0       0.17      0.09      0.12       824\n",
      "\n",
      "    accuracy                           0.26      2527\n",
      "   macro avg       0.24      0.26      0.24      2527\n",
      "weighted avg       0.24      0.26      0.24      2527\n",
      "\n",
      "\n",
      "--- Classification reports for 'ps_Entry/Exit_ema' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.54      0.77      0.63       217\n",
      "         0.0       0.66      0.39      0.49       205\n",
      "         1.0       0.45      0.43      0.44       183\n",
      "\n",
      "    accuracy                           0.54       605\n",
      "   macro avg       0.55      0.53      0.52       605\n",
      "weighted avg       0.55      0.54      0.53       605\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.50      0.78      0.61       780\n",
      "         0.0       0.66      0.35      0.46       823\n",
      "         1.0       0.46      0.43      0.44       815\n",
      "\n",
      "    accuracy                           0.51      2418\n",
      "   macro avg       0.54      0.52      0.50      2418\n",
      "weighted avg       0.54      0.51      0.50      2418\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.99      0.99      0.99       217\n",
      "         0.0       0.98      0.99      0.98       205\n",
      "         1.0       0.98      0.97      0.98       183\n",
      "\n",
      "    accuracy                           0.98       605\n",
      "   macro avg       0.98      0.98      0.98       605\n",
      "weighted avg       0.98      0.98      0.98       605\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       780\n",
      "         0.0       1.00      1.00      1.00       823\n",
      "         1.0       1.00      1.00      1.00       815\n",
      "\n",
      "    accuracy                           1.00      2418\n",
      "   macro avg       1.00      1.00      1.00      2418\n",
      "weighted avg       1.00      1.00      1.00      2418\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.54      0.40      0.46       217\n",
      "         0.0       0.32      0.44      0.37       205\n",
      "         1.0       0.43      0.38      0.40       183\n",
      "\n",
      "    accuracy                           0.41       605\n",
      "   macro avg       0.43      0.41      0.41       605\n",
      "weighted avg       0.43      0.41      0.41       605\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.49      0.41      0.45       780\n",
      "         0.0       0.32      0.45      0.38       823\n",
      "         1.0       0.46      0.36      0.40       815\n",
      "\n",
      "    accuracy                           0.41      2418\n",
      "   macro avg       0.43      0.41      0.41      2418\n",
      "weighted avg       0.43      0.41      0.41      2418\n",
      "\n",
      "\n",
      "--- Classification reports for 'pfcf_Entry/Exit_sma' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.58      0.69      0.63       253\n",
      "         0.0       0.66      0.49      0.56       202\n",
      "         1.0       0.48      0.49      0.49       209\n",
      "\n",
      "    accuracy                           0.57       664\n",
      "   macro avg       0.58      0.56      0.56       664\n",
      "weighted avg       0.58      0.57      0.57       664\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.57      0.70      0.63       916\n",
      "         0.0       0.70      0.51      0.59       893\n",
      "         1.0       0.52      0.55      0.54       847\n",
      "\n",
      "    accuracy                           0.59      2656\n",
      "   macro avg       0.60      0.59      0.59      2656\n",
      "weighted avg       0.60      0.59      0.59      2656\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.98      0.97      0.98       253\n",
      "         0.0       0.98      0.98      0.98       202\n",
      "         1.0       0.95      0.97      0.96       209\n",
      "\n",
      "    accuracy                           0.97       664\n",
      "   macro avg       0.97      0.97      0.97       664\n",
      "weighted avg       0.97      0.97      0.97       664\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       916\n",
      "         0.0       1.00      1.00      1.00       893\n",
      "         1.0       1.00      1.00      1.00       847\n",
      "\n",
      "    accuracy                           1.00      2656\n",
      "   macro avg       1.00      1.00      1.00      2656\n",
      "weighted avg       1.00      1.00      1.00      2656\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.49      0.79      0.61       253\n",
      "         0.0       0.46      0.47      0.46       202\n",
      "         1.0       0.28      0.07      0.11       209\n",
      "\n",
      "    accuracy                           0.47       664\n",
      "   macro avg       0.41      0.44      0.39       664\n",
      "weighted avg       0.42      0.47      0.41       664\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.47      0.79      0.59       916\n",
      "         0.0       0.49      0.51      0.50       893\n",
      "         1.0       0.30      0.07      0.11       847\n",
      "\n",
      "    accuracy                           0.47      2656\n",
      "   macro avg       0.42      0.46      0.40      2656\n",
      "weighted avg       0.42      0.47      0.41      2656\n",
      "\n",
      "\n",
      "--- Classification reports for 'pfcf_Entry/Exit_ema' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.41      0.46      0.43       251\n",
      "         0.0       0.64      0.35      0.45       198\n",
      "         1.0       0.32      0.42      0.36       192\n",
      "\n",
      "    accuracy                           0.41       641\n",
      "   macro avg       0.46      0.41      0.42       641\n",
      "weighted avg       0.45      0.41      0.42       641\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.38      0.50      0.43       889\n",
      "         0.0       0.68      0.35      0.46       853\n",
      "         1.0       0.39      0.45      0.42       822\n",
      "\n",
      "    accuracy                           0.44      2564\n",
      "   macro avg       0.48      0.43      0.44      2564\n",
      "weighted avg       0.48      0.44      0.44      2564\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.99      0.97      0.98       251\n",
      "         0.0       0.97      0.97      0.97       198\n",
      "         1.0       0.95      0.98      0.96       192\n",
      "\n",
      "    accuracy                           0.97       641\n",
      "   macro avg       0.97      0.97      0.97       641\n",
      "weighted avg       0.97      0.97      0.97       641\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       889\n",
      "         0.0       1.00      1.00      1.00       853\n",
      "         1.0       1.00      1.00      1.00       822\n",
      "\n",
      "    accuracy                           1.00      2564\n",
      "   macro avg       1.00      1.00      1.00      2564\n",
      "weighted avg       1.00      1.00      1.00      2564\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.44      0.47      0.45       251\n",
      "         0.0       0.44      0.32      0.37       198\n",
      "         1.0       0.36      0.44      0.40       192\n",
      "\n",
      "    accuracy                           0.41       641\n",
      "   macro avg       0.42      0.41      0.41       641\n",
      "weighted avg       0.42      0.41      0.41       641\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.41      0.48      0.44       889\n",
      "         0.0       0.49      0.32      0.39       853\n",
      "         1.0       0.37      0.44      0.40       822\n",
      "\n",
      "    accuracy                           0.41      2564\n",
      "   macro avg       0.42      0.41      0.41      2564\n",
      "weighted avg       0.42      0.41      0.41      2564\n",
      "\n",
      "\n",
      "--- Classification reports for 'pe_Entry/Exit_sma' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.74      0.54      0.63       259\n",
      "         0.0       0.63      0.58      0.60       212\n",
      "         1.0       0.60      0.85      0.70       207\n",
      "\n",
      "    accuracy                           0.65       678\n",
      "   macro avg       0.66      0.66      0.64       678\n",
      "weighted avg       0.66      0.65      0.64       678\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.70      0.53      0.61       930\n",
      "         0.0       0.64      0.53      0.58       898\n",
      "         1.0       0.59      0.84      0.70       881\n",
      "\n",
      "    accuracy                           0.63      2709\n",
      "   macro avg       0.64      0.63      0.63      2709\n",
      "weighted avg       0.64      0.63      0.63      2709\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.97      0.98      0.98       259\n",
      "         0.0       0.98      0.95      0.97       212\n",
      "         1.0       0.95      0.96      0.95       207\n",
      "\n",
      "    accuracy                           0.97       678\n",
      "   macro avg       0.97      0.97      0.97       678\n",
      "weighted avg       0.97      0.97      0.97       678\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       930\n",
      "         0.0       1.00      1.00      1.00       898\n",
      "         1.0       1.00      1.00      1.00       881\n",
      "\n",
      "    accuracy                           1.00      2709\n",
      "   macro avg       1.00      1.00      1.00      2709\n",
      "weighted avg       1.00      1.00      1.00      2709\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.49      0.50      0.50       259\n",
      "         0.0       0.48      0.57      0.52       212\n",
      "         1.0       0.49      0.39      0.44       207\n",
      "\n",
      "    accuracy                           0.49       678\n",
      "   macro avg       0.49      0.49      0.48       678\n",
      "weighted avg       0.49      0.49      0.49       678\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.49      0.58      0.53       930\n",
      "         0.0       0.48      0.53      0.50       898\n",
      "         1.0       0.53      0.37      0.43       881\n",
      "\n",
      "    accuracy                           0.49      2709\n",
      "   macro avg       0.50      0.49      0.49      2709\n",
      "weighted avg       0.50      0.49      0.49      2709\n",
      "\n",
      "\n",
      "--- Classification reports for 'pe_Entry/Exit_ema' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.48      0.67      0.56       244\n",
      "         0.0       0.72      0.51      0.59       213\n",
      "         1.0       0.21      0.17      0.18       181\n",
      "\n",
      "    accuracy                           0.47       638\n",
      "   macro avg       0.47      0.45      0.45       638\n",
      "weighted avg       0.48      0.47      0.46       638\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.44      0.72      0.55       864\n",
      "         0.0       0.73      0.51      0.60       877\n",
      "         1.0       0.27      0.18      0.21       807\n",
      "\n",
      "    accuracy                           0.48      2548\n",
      "   macro avg       0.48      0.47      0.45      2548\n",
      "weighted avg       0.49      0.48      0.46      2548\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.98      0.98      0.98       244\n",
      "         0.0       0.98      0.98      0.98       213\n",
      "         1.0       0.97      0.97      0.97       181\n",
      "\n",
      "    accuracy                           0.97       638\n",
      "   macro avg       0.97      0.97      0.97       638\n",
      "weighted avg       0.97      0.97      0.97       638\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       864\n",
      "         0.0       1.00      1.00      1.00       877\n",
      "         1.0       1.00      1.00      1.00       807\n",
      "\n",
      "    accuracy                           1.00      2548\n",
      "   macro avg       1.00      1.00      1.00      2548\n",
      "weighted avg       1.00      1.00      1.00      2548\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.27      0.28      0.28       244\n",
      "         0.0       0.18      0.21      0.19       213\n",
      "         1.0       0.31      0.22      0.26       181\n",
      "\n",
      "    accuracy                           0.24       638\n",
      "   macro avg       0.25      0.24      0.24       638\n",
      "weighted avg       0.25      0.24      0.24       638\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.18      0.20      0.19       864\n",
      "         0.0       0.19      0.23      0.21       877\n",
      "         1.0       0.36      0.25      0.29       807\n",
      "\n",
      "    accuracy                           0.22      2548\n",
      "   macro avg       0.24      0.22      0.23      2548\n",
      "weighted avg       0.24      0.22      0.23      2548\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define models\n",
    "logistic_regression = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "models = {'Naive Bayes': GaussianNB(),\n",
    "          'Random Forest Classifier': RandomForestClassifier(random_state=42),\n",
    "          'Logistic Regression': logistic_regression}\n",
    "\n",
    "# Create an empty DataFrame to store the classification reports\n",
    "reports_df_test = pd.DataFrame()\n",
    "reports_df_train = pd.DataFrame()\n",
    "\n",
    "# Loop through each y variable\n",
    "for y_var in y_variables:\n",
    "    print(f\"\\n--- Classification reports for '{y_var}' ---\\n\")\n",
    "    \n",
    "    # Drop NaN values from X and y for the current y variable\n",
    "    data_cleaned = nvda_df.dropna(subset=features + [y_var])\n",
    "    X = data_cleaned[features]\n",
    "    y = data_cleaned[y_var]\n",
    "\n",
    "    # Apply SMOTEENN to address class imbalance\n",
    "    smoteenn = SMOTEENN(random_state=42)\n",
    "    X_resampled, y_resampled = smoteenn.fit_resample(X, y)\n",
    "\n",
    "    # Split the resampled data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Scale the features using StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Loop through each model\n",
    "    for model_name, model in models.items():\n",
    "        # Train the model on the training data\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "\n",
    "        # Make predictions on the testing data\n",
    "        y_pred_test = model.predict(X_test_scaled)\n",
    "\n",
    "        # Print label for the model\n",
    "        print(f\"\\n--- {model_name} --- (Testing Data)\")\n",
    "\n",
    "        # Print classification report for testing data\n",
    "        print(classification_report(y_test, y_pred_test))\n",
    "        \n",
    "        # Store classification report for testing data in the DataFrame\n",
    "        report_test = classification_report(y_test, y_pred_test, output_dict=True)\n",
    "        report_df_test = pd.DataFrame(report_test).transpose()\n",
    "        report_df_test['y_variable'] = y_var\n",
    "        report_df_test['model'] = model_name\n",
    "        reports_df_test = pd.concat([reports_df_test, report_df_test])\n",
    "\n",
    "        # Make predictions on the training data\n",
    "        y_pred_train = model.predict(X_train_scaled)\n",
    "\n",
    "        # Print label for the model\n",
    "        print(f\"\\n--- {model_name} --- (Training Data)\")\n",
    "\n",
    "        # Print classification report for training data\n",
    "        print(classification_report(y_train, y_pred_train))\n",
    "\n",
    "        # Store classification report for training data in the DataFrame\n",
    "        report_train = classification_report(y_train, y_pred_train, output_dict=True)\n",
    "        report_df_train = pd.DataFrame(report_train).transpose()\n",
    "        report_df_train['y_variable'] = y_var\n",
    "        report_df_train['model'] = model_name\n",
    "        reports_df_train = pd.concat([reports_df_train, report_df_train])\n",
    "\n",
    "# Export the DataFrames containing classification reports to separate CSV files\n",
    "reports_df_test.to_csv('testing_classification_reports_NVDA_10.csv', index=True)\n",
    "reports_df_train.to_csv('training_classification_reports_NVDA_10.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MMM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) \n",
    "features = ['MMM P/S (LTM)', 'MMM P/FCF (LTM)', 'MMM P/E (LTM)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define y variables\n",
    "y_variables = ['ps_Entry/Exit_sma', 'ps_Entry/Exit_ema', 'pfcf_Entry/Exit_sma',\n",
    "               'pfcf_Entry/Exit_ema', 'pe_Entry/Exit_sma', 'pe_Entry/Exit_ema']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Classification reports for 'ps_Entry/Exit_sma' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.59      0.32      0.42       196\n",
      "         0.0       0.56      0.39      0.46       183\n",
      "         1.0       0.49      0.86      0.62       191\n",
      "\n",
      "    accuracy                           0.52       570\n",
      "   macro avg       0.55      0.52      0.50       570\n",
      "weighted avg       0.55      0.52      0.50       570\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.60      0.36      0.45       743\n",
      "         0.0       0.62      0.44      0.52       749\n",
      "         1.0       0.51      0.85      0.64       786\n",
      "\n",
      "    accuracy                           0.55      2278\n",
      "   macro avg       0.58      0.55      0.53      2278\n",
      "weighted avg       0.58      0.55      0.54      2278\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.96      0.97      0.97       196\n",
      "         0.0       0.97      0.92      0.95       183\n",
      "         1.0       0.96      0.99      0.97       191\n",
      "\n",
      "    accuracy                           0.96       570\n",
      "   macro avg       0.96      0.96      0.96       570\n",
      "weighted avg       0.96      0.96      0.96       570\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       743\n",
      "         0.0       1.00      1.00      1.00       749\n",
      "         1.0       1.00      1.00      1.00       786\n",
      "\n",
      "    accuracy                           1.00      2278\n",
      "   macro avg       1.00      1.00      1.00      2278\n",
      "weighted avg       1.00      1.00      1.00      2278\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.39      0.21      0.28       196\n",
      "         0.0       0.24      0.17      0.20       183\n",
      "         1.0       0.40      0.69      0.51       191\n",
      "\n",
      "    accuracy                           0.36       570\n",
      "   macro avg       0.34      0.36      0.33       570\n",
      "weighted avg       0.34      0.36      0.33       570\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.42      0.26      0.32       743\n",
      "         0.0       0.29      0.21      0.24       749\n",
      "         1.0       0.43      0.71      0.54       786\n",
      "\n",
      "    accuracy                           0.40      2278\n",
      "   macro avg       0.38      0.39      0.37      2278\n",
      "weighted avg       0.38      0.40      0.37      2278\n",
      "\n",
      "\n",
      "--- Classification reports for 'ps_Entry/Exit_ema' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.66      0.47      0.55       189\n",
      "         0.0       0.59      0.68      0.63       201\n",
      "         1.0       0.48      0.54      0.50       190\n",
      "\n",
      "    accuracy                           0.57       580\n",
      "   macro avg       0.58      0.56      0.56       580\n",
      "weighted avg       0.58      0.57      0.56       580\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.61      0.44      0.51       762\n",
      "         0.0       0.57      0.69      0.62       781\n",
      "         1.0       0.47      0.50      0.49       773\n",
      "\n",
      "    accuracy                           0.54      2316\n",
      "   macro avg       0.55      0.54      0.54      2316\n",
      "weighted avg       0.55      0.54      0.54      2316\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.96      1.00      0.98       189\n",
      "         0.0       1.00      0.97      0.98       201\n",
      "         1.0       0.98      0.98      0.98       190\n",
      "\n",
      "    accuracy                           0.98       580\n",
      "   macro avg       0.98      0.98      0.98       580\n",
      "weighted avg       0.98      0.98      0.98       580\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       762\n",
      "         0.0       1.00      1.00      1.00       781\n",
      "         1.0       1.00      1.00      1.00       773\n",
      "\n",
      "    accuracy                           1.00      2316\n",
      "   macro avg       1.00      1.00      1.00      2316\n",
      "weighted avg       1.00      1.00      1.00      2316\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.57      0.64      0.60       189\n",
      "         0.0       0.70      0.78      0.74       201\n",
      "         1.0       0.57      0.44      0.49       190\n",
      "\n",
      "    accuracy                           0.62       580\n",
      "   macro avg       0.62      0.62      0.61       580\n",
      "weighted avg       0.62      0.62      0.62       580\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.54      0.61      0.58       762\n",
      "         0.0       0.73      0.81      0.77       781\n",
      "         1.0       0.54      0.41      0.46       773\n",
      "\n",
      "    accuracy                           0.61      2316\n",
      "   macro avg       0.60      0.61      0.60      2316\n",
      "weighted avg       0.60      0.61      0.60      2316\n",
      "\n",
      "\n",
      "--- Classification reports for 'pfcf_Entry/Exit_sma' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.58      0.84      0.69       186\n",
      "         0.0       0.78      0.35      0.49       186\n",
      "         1.0       0.67      0.74      0.70       182\n",
      "\n",
      "    accuracy                           0.64       554\n",
      "   macro avg       0.68      0.65      0.63       554\n",
      "weighted avg       0.68      0.64      0.63       554\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.59      0.81      0.68       752\n",
      "         0.0       0.72      0.42      0.53       716\n",
      "         1.0       0.65      0.66      0.66       748\n",
      "\n",
      "    accuracy                           0.63      2216\n",
      "   macro avg       0.65      0.63      0.62      2216\n",
      "weighted avg       0.65      0.63      0.62      2216\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.96      0.99      0.98       186\n",
      "         0.0       1.00      0.94      0.97       186\n",
      "         1.0       0.96      0.99      0.98       182\n",
      "\n",
      "    accuracy                           0.97       554\n",
      "   macro avg       0.97      0.97      0.97       554\n",
      "weighted avg       0.97      0.97      0.97       554\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       752\n",
      "         0.0       1.00      1.00      1.00       716\n",
      "         1.0       1.00      1.00      1.00       748\n",
      "\n",
      "    accuracy                           1.00      2216\n",
      "   macro avg       1.00      1.00      1.00      2216\n",
      "weighted avg       1.00      1.00      1.00      2216\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.55      0.74      0.63       186\n",
      "         0.0       0.49      0.22      0.30       186\n",
      "         1.0       0.63      0.78      0.70       182\n",
      "\n",
      "    accuracy                           0.58       554\n",
      "   macro avg       0.56      0.58      0.54       554\n",
      "weighted avg       0.56      0.58      0.54       554\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.58      0.74      0.65       752\n",
      "         0.0       0.48      0.26      0.34       716\n",
      "         1.0       0.65      0.75      0.69       748\n",
      "\n",
      "    accuracy                           0.59      2216\n",
      "   macro avg       0.57      0.58      0.56      2216\n",
      "weighted avg       0.57      0.59      0.56      2216\n",
      "\n",
      "\n",
      "--- Classification reports for 'pfcf_Entry/Exit_ema' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.41      0.59      0.48       159\n",
      "         0.0       0.52      0.43      0.47       152\n",
      "         1.0       0.26      0.19      0.22       171\n",
      "\n",
      "    accuracy                           0.40       482\n",
      "   macro avg       0.40      0.40      0.39       482\n",
      "weighted avg       0.39      0.40      0.39       482\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.38      0.56      0.45       626\n",
      "         0.0       0.58      0.42      0.49       642\n",
      "         1.0       0.31      0.26      0.29       660\n",
      "\n",
      "    accuracy                           0.41      1928\n",
      "   macro avg       0.43      0.41      0.41      1928\n",
      "weighted avg       0.43      0.41      0.41      1928\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.96      0.98      0.97       159\n",
      "         0.0       0.99      0.96      0.97       152\n",
      "         1.0       0.98      0.98      0.98       171\n",
      "\n",
      "    accuracy                           0.98       482\n",
      "   macro avg       0.98      0.97      0.97       482\n",
      "weighted avg       0.98      0.98      0.98       482\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       626\n",
      "         0.0       1.00      1.00      1.00       642\n",
      "         1.0       1.00      1.00      1.00       660\n",
      "\n",
      "    accuracy                           1.00      1928\n",
      "   macro avg       1.00      1.00      1.00      1928\n",
      "weighted avg       1.00      1.00      1.00      1928\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.40      0.39      0.40       159\n",
      "         0.0       0.45      0.43      0.44       152\n",
      "         1.0       0.30      0.32      0.31       171\n",
      "\n",
      "    accuracy                           0.38       482\n",
      "   macro avg       0.38      0.38      0.38       482\n",
      "weighted avg       0.38      0.38      0.38       482\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.38      0.34      0.36       626\n",
      "         0.0       0.51      0.42      0.46       642\n",
      "         1.0       0.33      0.41      0.36       660\n",
      "\n",
      "    accuracy                           0.39      1928\n",
      "   macro avg       0.40      0.39      0.40      1928\n",
      "weighted avg       0.40      0.39      0.40      1928\n",
      "\n",
      "\n",
      "--- Classification reports for 'pe_Entry/Exit_sma' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.61      0.66      0.63       169\n",
      "         0.0       0.66      0.36      0.47       165\n",
      "         1.0       0.59      0.80      0.68       164\n",
      "\n",
      "    accuracy                           0.61       498\n",
      "   macro avg       0.62      0.61      0.59       498\n",
      "weighted avg       0.62      0.61      0.59       498\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.65      0.71      0.68       653\n",
      "         0.0       0.65      0.36      0.46       675\n",
      "         1.0       0.57      0.79      0.67       661\n",
      "\n",
      "    accuracy                           0.62      1989\n",
      "   macro avg       0.63      0.62      0.60      1989\n",
      "weighted avg       0.63      0.62      0.60      1989\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.97      0.99      0.98       169\n",
      "         0.0       0.98      0.98      0.98       165\n",
      "         1.0       0.98      0.96      0.97       164\n",
      "\n",
      "    accuracy                           0.98       498\n",
      "   macro avg       0.98      0.98      0.98       498\n",
      "weighted avg       0.98      0.98      0.98       498\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       653\n",
      "         0.0       1.00      1.00      1.00       675\n",
      "         1.0       1.00      1.00      1.00       661\n",
      "\n",
      "    accuracy                           1.00      1989\n",
      "   macro avg       1.00      1.00      1.00      1989\n",
      "weighted avg       1.00      1.00      1.00      1989\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.74      0.50      0.59       169\n",
      "         0.0       0.52      0.56      0.54       165\n",
      "         1.0       0.57      0.71      0.63       164\n",
      "\n",
      "    accuracy                           0.59       498\n",
      "   macro avg       0.61      0.59      0.59       498\n",
      "weighted avg       0.61      0.59      0.59       498\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.75      0.53      0.62       653\n",
      "         0.0       0.55      0.54      0.54       675\n",
      "         1.0       0.56      0.73      0.64       661\n",
      "\n",
      "    accuracy                           0.60      1989\n",
      "   macro avg       0.62      0.60      0.60      1989\n",
      "weighted avg       0.62      0.60      0.60      1989\n",
      "\n",
      "\n",
      "--- Classification reports for 'pe_Entry/Exit_ema' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.42      0.26      0.32       167\n",
      "         0.0       0.87      0.44      0.58       187\n",
      "         1.0       0.39      0.77      0.52       163\n",
      "\n",
      "    accuracy                           0.49       517\n",
      "   macro avg       0.56      0.49      0.48       517\n",
      "weighted avg       0.58      0.49      0.48       517\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.37      0.21      0.27       665\n",
      "         0.0       0.82      0.42      0.56       683\n",
      "         1.0       0.43      0.79      0.56       716\n",
      "\n",
      "    accuracy                           0.48      2064\n",
      "   macro avg       0.54      0.48      0.46      2064\n",
      "weighted avg       0.54      0.48      0.46      2064\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.97      0.93      0.95       167\n",
      "         0.0       0.96      0.98      0.97       187\n",
      "         1.0       0.96      0.98      0.97       163\n",
      "\n",
      "    accuracy                           0.97       517\n",
      "   macro avg       0.97      0.96      0.96       517\n",
      "weighted avg       0.97      0.97      0.97       517\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       665\n",
      "         0.0       1.00      1.00      1.00       683\n",
      "         1.0       1.00      1.00      1.00       716\n",
      "\n",
      "    accuracy                           1.00      2064\n",
      "   macro avg       1.00      1.00      1.00      2064\n",
      "weighted avg       1.00      1.00      1.00      2064\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.53      0.43      0.47       167\n",
      "         0.0       0.92      0.52      0.67       187\n",
      "         1.0       0.42      0.71      0.52       163\n",
      "\n",
      "    accuracy                           0.55       517\n",
      "   macro avg       0.62      0.55      0.55       517\n",
      "weighted avg       0.64      0.55      0.56       517\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.56      0.48      0.51       665\n",
      "         0.0       0.83      0.53      0.64       683\n",
      "         1.0       0.50      0.74      0.60       716\n",
      "\n",
      "    accuracy                           0.58      2064\n",
      "   macro avg       0.63      0.58      0.58      2064\n",
      "weighted avg       0.63      0.58      0.59      2064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define models\n",
    "logistic_regression = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "models = {'Naive Bayes': GaussianNB(),\n",
    "          'Random Forest Classifier': RandomForestClassifier(random_state=42),\n",
    "          'Logistic Regression': logistic_regression}\n",
    "\n",
    "# Create an empty DataFrame to store the classification reports\n",
    "reports_df_test = pd.DataFrame()\n",
    "reports_df_train = pd.DataFrame()\n",
    "\n",
    "# Loop through each y variable\n",
    "for y_var in y_variables:\n",
    "    print(f\"\\n--- Classification reports for '{y_var}' ---\\n\")\n",
    "    \n",
    "    # Drop NaN values from X and y for the current y variable\n",
    "    data_cleaned = mmm_df.dropna(subset=features + [y_var])\n",
    "    X = data_cleaned[features]\n",
    "    y = data_cleaned[y_var]\n",
    "\n",
    "    # Apply SMOTEENN to address class imbalance\n",
    "    smoteenn = SMOTEENN(random_state=42)\n",
    "    X_resampled, y_resampled = smoteenn.fit_resample(X, y)\n",
    "\n",
    "    # Split the resampled data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Scale the features using StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Loop through each model\n",
    "    for model_name, model in models.items():\n",
    "        # Train the model on the training data\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "\n",
    "        # Make predictions on the testing data\n",
    "        y_pred_test = model.predict(X_test_scaled)\n",
    "\n",
    "        # Print label for the model\n",
    "        print(f\"\\n--- {model_name} --- (Testing Data)\")\n",
    "\n",
    "        # Print classification report for testing data\n",
    "        print(classification_report(y_test, y_pred_test))\n",
    "        \n",
    "        # Store classification report for testing data in the DataFrame\n",
    "        report_test = classification_report(y_test, y_pred_test, output_dict=True)\n",
    "        report_df_test = pd.DataFrame(report_test).transpose()\n",
    "        report_df_test['y_variable'] = y_var\n",
    "        report_df_test['model'] = model_name\n",
    "        reports_df_test = pd.concat([reports_df_test, report_df_test])\n",
    "\n",
    "        # Make predictions on the training data\n",
    "        y_pred_train = model.predict(X_train_scaled)\n",
    "\n",
    "        # Print label for the model\n",
    "        print(f\"\\n--- {model_name} --- (Training Data)\")\n",
    "\n",
    "        # Print classification report for training data\n",
    "        print(classification_report(y_train, y_pred_train))\n",
    "\n",
    "        # Store classification report for training data in the DataFrame\n",
    "        report_train = classification_report(y_train, y_pred_train, output_dict=True)\n",
    "        report_df_train = pd.DataFrame(report_train).transpose()\n",
    "        report_df_train['y_variable'] = y_var\n",
    "        report_df_train['model'] = model_name\n",
    "        reports_df_train = pd.concat([reports_df_train, report_df_train])\n",
    "\n",
    "# Export the DataFrames containing classification reports to separate CSV files\n",
    "reports_df_test.to_csv('testing_classification_reports_MMM_10.csv', index=True)\n",
    "reports_df_train.to_csv('training_classification_reports_MMM_10.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) \n",
    "features = ['PG P/S (LTM)', 'PG P/FCF (LTM)', 'PG P/E (LTM)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define y variables\n",
    "y_variables = ['ps_Entry/Exit_sma', 'ps_Entry/Exit_ema', 'pfcf_Entry/Exit_sma',\n",
    "               'pfcf_Entry/Exit_ema', 'pe_Entry/Exit_sma', 'pe_Entry/Exit_ema']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Classification reports for 'ps_Entry/Exit_sma' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.50      0.63      0.56       174\n",
      "         0.0       0.71      0.47      0.57       189\n",
      "         1.0       0.38      0.42      0.40       163\n",
      "\n",
      "    accuracy                           0.51       526\n",
      "   macro avg       0.53      0.51      0.51       526\n",
      "weighted avg       0.54      0.51      0.51       526\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.51      0.65      0.57       671\n",
      "         0.0       0.75      0.50      0.60       768\n",
      "         1.0       0.45      0.50      0.48       663\n",
      "\n",
      "    accuracy                           0.55      2102\n",
      "   macro avg       0.57      0.55      0.55      2102\n",
      "weighted avg       0.58      0.55      0.55      2102\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.96      0.99      0.97       174\n",
      "         0.0       0.99      0.97      0.98       189\n",
      "         1.0       0.99      0.98      0.98       163\n",
      "\n",
      "    accuracy                           0.98       526\n",
      "   macro avg       0.98      0.98      0.98       526\n",
      "weighted avg       0.98      0.98      0.98       526\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       671\n",
      "         0.0       1.00      1.00      1.00       768\n",
      "         1.0       1.00      1.00      1.00       663\n",
      "\n",
      "    accuracy                           1.00      2102\n",
      "   macro avg       1.00      1.00      1.00      2102\n",
      "weighted avg       1.00      1.00      1.00      2102\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.48      0.62      0.54       174\n",
      "         0.0       0.55      0.63      0.59       189\n",
      "         1.0       0.29      0.15      0.20       163\n",
      "\n",
      "    accuracy                           0.48       526\n",
      "   macro avg       0.44      0.47      0.44       526\n",
      "weighted avg       0.45      0.48      0.45       526\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.47      0.64      0.54       671\n",
      "         0.0       0.51      0.57      0.54       768\n",
      "         1.0       0.34      0.17      0.23       663\n",
      "\n",
      "    accuracy                           0.47      2102\n",
      "   macro avg       0.44      0.46      0.44      2102\n",
      "weighted avg       0.44      0.47      0.44      2102\n",
      "\n",
      "\n",
      "--- Classification reports for 'ps_Entry/Exit_ema' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.43      0.67      0.52       201\n",
      "         0.0       0.78      0.22      0.34       203\n",
      "         1.0       0.40      0.45      0.42       211\n",
      "\n",
      "    accuracy                           0.45       615\n",
      "   macro avg       0.53      0.45      0.43       615\n",
      "weighted avg       0.53      0.45      0.43       615\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.41      0.65      0.50       759\n",
      "         0.0       0.83      0.23      0.36       860\n",
      "         1.0       0.36      0.44      0.40       837\n",
      "\n",
      "    accuracy                           0.43      2456\n",
      "   macro avg       0.54      0.44      0.42      2456\n",
      "weighted avg       0.54      0.43      0.42      2456\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.99      0.97      0.98       201\n",
      "         0.0       0.99      0.98      0.98       203\n",
      "         1.0       0.96      1.00      0.98       211\n",
      "\n",
      "    accuracy                           0.98       615\n",
      "   macro avg       0.98      0.98      0.98       615\n",
      "weighted avg       0.98      0.98      0.98       615\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       759\n",
      "         0.0       1.00      1.00      1.00       860\n",
      "         1.0       1.00      1.00      1.00       837\n",
      "\n",
      "    accuracy                           1.00      2456\n",
      "   macro avg       1.00      1.00      1.00      2456\n",
      "weighted avg       1.00      1.00      1.00      2456\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.42      0.47      0.44       201\n",
      "         0.0       0.47      0.45      0.46       203\n",
      "         1.0       0.32      0.29      0.30       211\n",
      "\n",
      "    accuracy                           0.40       615\n",
      "   macro avg       0.40      0.40      0.40       615\n",
      "weighted avg       0.40      0.40      0.40       615\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.42      0.49      0.45       759\n",
      "         0.0       0.51      0.48      0.50       860\n",
      "         1.0       0.34      0.30      0.32       837\n",
      "\n",
      "    accuracy                           0.42      2456\n",
      "   macro avg       0.42      0.43      0.42      2456\n",
      "weighted avg       0.42      0.42      0.42      2456\n",
      "\n",
      "\n",
      "--- Classification reports for 'pfcf_Entry/Exit_sma' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.51      0.39      0.44       211\n",
      "         0.0       0.67      0.54      0.60       210\n",
      "         1.0       0.48      0.69      0.56       199\n",
      "\n",
      "    accuracy                           0.54       620\n",
      "   macro avg       0.55      0.54      0.54       620\n",
      "weighted avg       0.55      0.54      0.54       620\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.47      0.40      0.43       761\n",
      "         0.0       0.72      0.57      0.64       918\n",
      "         1.0       0.47      0.65      0.55       801\n",
      "\n",
      "    accuracy                           0.54      2480\n",
      "   macro avg       0.55      0.54      0.54      2480\n",
      "weighted avg       0.56      0.54      0.54      2480\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.98      0.98      0.98       211\n",
      "         0.0       0.99      0.97      0.98       210\n",
      "         1.0       0.98      0.99      0.99       199\n",
      "\n",
      "    accuracy                           0.98       620\n",
      "   macro avg       0.98      0.98      0.98       620\n",
      "weighted avg       0.98      0.98      0.98       620\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       761\n",
      "         0.0       1.00      1.00      1.00       918\n",
      "         1.0       1.00      1.00      1.00       801\n",
      "\n",
      "    accuracy                           1.00      2480\n",
      "   macro avg       1.00      1.00      1.00      2480\n",
      "weighted avg       1.00      1.00      1.00      2480\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.50      0.39      0.44       211\n",
      "         0.0       0.33      0.52      0.40       210\n",
      "         1.0       0.43      0.25      0.32       199\n",
      "\n",
      "    accuracy                           0.39       620\n",
      "   macro avg       0.42      0.39      0.39       620\n",
      "weighted avg       0.42      0.39      0.39       620\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.43      0.39      0.41       761\n",
      "         0.0       0.35      0.49      0.41       918\n",
      "         1.0       0.41      0.25      0.31       801\n",
      "\n",
      "    accuracy                           0.38      2480\n",
      "   macro avg       0.40      0.38      0.38      2480\n",
      "weighted avg       0.39      0.38      0.38      2480\n",
      "\n",
      "\n",
      "--- Classification reports for 'pfcf_Entry/Exit_ema' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.49      0.58      0.53       182\n",
      "         0.0       0.47      0.49      0.48       206\n",
      "         1.0       0.49      0.38      0.43       185\n",
      "\n",
      "    accuracy                           0.48       573\n",
      "   macro avg       0.48      0.48      0.48       573\n",
      "weighted avg       0.48      0.48      0.48       573\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.50      0.61      0.55       714\n",
      "         0.0       0.48      0.47      0.48       854\n",
      "         1.0       0.46      0.37      0.41       724\n",
      "\n",
      "    accuracy                           0.48      2292\n",
      "   macro avg       0.48      0.48      0.48      2292\n",
      "weighted avg       0.48      0.48      0.48      2292\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.97      0.96      0.96       182\n",
      "         0.0       0.98      0.99      0.98       206\n",
      "         1.0       0.98      0.98      0.98       185\n",
      "\n",
      "    accuracy                           0.98       573\n",
      "   macro avg       0.98      0.98      0.98       573\n",
      "weighted avg       0.98      0.98      0.98       573\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       714\n",
      "         0.0       1.00      1.00      1.00       854\n",
      "         1.0       1.00      1.00      1.00       724\n",
      "\n",
      "    accuracy                           1.00      2292\n",
      "   macro avg       1.00      1.00      1.00      2292\n",
      "weighted avg       1.00      1.00      1.00      2292\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.54      0.51      0.52       182\n",
      "         0.0       0.47      0.78      0.59       206\n",
      "         1.0       0.46      0.16      0.23       185\n",
      "\n",
      "    accuracy                           0.49       573\n",
      "   macro avg       0.49      0.48      0.45       573\n",
      "weighted avg       0.49      0.49      0.45       573\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.52      0.52      0.52       714\n",
      "         0.0       0.47      0.73      0.57       854\n",
      "         1.0       0.40      0.14      0.21       724\n",
      "\n",
      "    accuracy                           0.48      2292\n",
      "   macro avg       0.46      0.46      0.43      2292\n",
      "weighted avg       0.46      0.48      0.44      2292\n",
      "\n",
      "\n",
      "--- Classification reports for 'pe_Entry/Exit_sma' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.51      0.54      0.52       209\n",
      "         0.0       0.84      0.52      0.64       208\n",
      "         1.0       0.47      0.64      0.54       184\n",
      "\n",
      "    accuracy                           0.56       601\n",
      "   macro avg       0.61      0.57      0.57       601\n",
      "weighted avg       0.61      0.56      0.57       601\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.42      0.49      0.45       724\n",
      "         0.0       0.81      0.49      0.61       873\n",
      "         1.0       0.47      0.59      0.52       803\n",
      "\n",
      "    accuracy                           0.52      2400\n",
      "   macro avg       0.56      0.52      0.53      2400\n",
      "weighted avg       0.58      0.52      0.53      2400\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.96      0.95      0.95       209\n",
      "         0.0       0.99      0.96      0.98       208\n",
      "         1.0       0.93      0.99      0.96       184\n",
      "\n",
      "    accuracy                           0.96       601\n",
      "   macro avg       0.96      0.96      0.96       601\n",
      "weighted avg       0.96      0.96      0.96       601\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       724\n",
      "         0.0       1.00      1.00      1.00       873\n",
      "         1.0       1.00      1.00      1.00       803\n",
      "\n",
      "    accuracy                           1.00      2400\n",
      "   macro avg       1.00      1.00      1.00      2400\n",
      "weighted avg       1.00      1.00      1.00      2400\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.51      0.40      0.45       209\n",
      "         0.0       0.59      0.50      0.54       208\n",
      "         1.0       0.48      0.68      0.57       184\n",
      "\n",
      "    accuracy                           0.52       601\n",
      "   macro avg       0.53      0.53      0.52       601\n",
      "weighted avg       0.53      0.52      0.52       601\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.42      0.36      0.39       724\n",
      "         0.0       0.58      0.53      0.55       873\n",
      "         1.0       0.51      0.62      0.56       803\n",
      "\n",
      "    accuracy                           0.51      2400\n",
      "   macro avg       0.50      0.50      0.50      2400\n",
      "weighted avg       0.51      0.51      0.51      2400\n",
      "\n",
      "\n",
      "--- Classification reports for 'pe_Entry/Exit_ema' ---\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.39      0.59      0.47       216\n",
      "         0.0       0.75      0.22      0.34       210\n",
      "         1.0       0.39      0.46      0.42       200\n",
      "\n",
      "    accuracy                           0.43       626\n",
      "   macro avg       0.51      0.43      0.41       626\n",
      "weighted avg       0.51      0.43      0.41       626\n",
      "\n",
      "\n",
      "--- Naive Bayes --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.37      0.60      0.46       777\n",
      "         0.0       0.72      0.21      0.33       894\n",
      "         1.0       0.46      0.54      0.50       833\n",
      "\n",
      "    accuracy                           0.44      2504\n",
      "   macro avg       0.52      0.45      0.43      2504\n",
      "weighted avg       0.52      0.44      0.42      2504\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.96      0.98      0.97       216\n",
      "         0.0       0.98      0.98      0.98       210\n",
      "         1.0       0.98      0.96      0.97       200\n",
      "\n",
      "    accuracy                           0.97       626\n",
      "   macro avg       0.97      0.97      0.97       626\n",
      "weighted avg       0.97      0.97      0.97       626\n",
      "\n",
      "\n",
      "--- Random Forest Classifier --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00       777\n",
      "         0.0       1.00      1.00      1.00       894\n",
      "         1.0       1.00      1.00      1.00       833\n",
      "\n",
      "    accuracy                           1.00      2504\n",
      "   macro avg       1.00      1.00      1.00      2504\n",
      "weighted avg       1.00      1.00      1.00      2504\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Testing Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.55      0.31      0.39       216\n",
      "         0.0       0.44      0.55      0.49       210\n",
      "         1.0       0.41      0.50      0.45       200\n",
      "\n",
      "    accuracy                           0.45       626\n",
      "   macro avg       0.47      0.45      0.44       626\n",
      "weighted avg       0.47      0.45      0.44       626\n",
      "\n",
      "\n",
      "--- Logistic Regression --- (Training Data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.48      0.33      0.39       777\n",
      "         0.0       0.50      0.58      0.54       894\n",
      "         1.0       0.44      0.49      0.47       833\n",
      "\n",
      "    accuracy                           0.47      2504\n",
      "   macro avg       0.47      0.47      0.47      2504\n",
      "weighted avg       0.47      0.47      0.47      2504\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define models\n",
    "logistic_regression = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "models = {'Naive Bayes': GaussianNB(),\n",
    "          'Random Forest Classifier': RandomForestClassifier(random_state=42),\n",
    "          'Logistic Regression': logistic_regression}\n",
    "\n",
    "# Create an empty DataFrame to store the classification reports\n",
    "reports_df_test = pd.DataFrame()\n",
    "reports_df_train = pd.DataFrame()\n",
    "\n",
    "# Loop through each y variable\n",
    "for y_var in y_variables:\n",
    "    print(f\"\\n--- Classification reports for '{y_var}' ---\\n\")\n",
    "    \n",
    "    # Drop NaN values from X and y for the current y variable\n",
    "    data_cleaned = pg_df.dropna(subset=features + [y_var])\n",
    "    X = data_cleaned[features]\n",
    "    y = data_cleaned[y_var]\n",
    "\n",
    "    # Apply SMOTEENN to address class imbalance\n",
    "    smoteenn = SMOTEENN(random_state=42)\n",
    "    X_resampled, y_resampled = smoteenn.fit_resample(X, y)\n",
    "\n",
    "    # Split the resampled data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Scale the features using StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Loop through each model\n",
    "    for model_name, model in models.items():\n",
    "        # Train the model on the training data\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "\n",
    "        # Make predictions on the testing data\n",
    "        y_pred_test = model.predict(X_test_scaled)\n",
    "\n",
    "        # Print label for the model\n",
    "        print(f\"\\n--- {model_name} --- (Testing Data)\")\n",
    "\n",
    "        # Print classification report for testing data\n",
    "        print(classification_report(y_test, y_pred_test))\n",
    "        \n",
    "        # Store classification report for testing data in the DataFrame\n",
    "        report_test = classification_report(y_test, y_pred_test, output_dict=True)\n",
    "        report_df_test = pd.DataFrame(report_test).transpose()\n",
    "        report_df_test['y_variable'] = y_var\n",
    "        report_df_test['model'] = model_name\n",
    "        reports_df_test = pd.concat([reports_df_test, report_df_test])\n",
    "\n",
    "        # Make predictions on the training data\n",
    "        y_pred_train = model.predict(X_train_scaled)\n",
    "\n",
    "        # Print label for the model\n",
    "        print(f\"\\n--- {model_name} --- (Training Data)\")\n",
    "\n",
    "        # Print classification report for training data\n",
    "        print(classification_report(y_train, y_pred_train))\n",
    "\n",
    "        # Store classification report for training data in the DataFrame\n",
    "        report_train = classification_report(y_train, y_pred_train, output_dict=True)\n",
    "        report_df_train = pd.DataFrame(report_train).transpose()\n",
    "        report_df_train['y_variable'] = y_var\n",
    "        report_df_train['model'] = model_name\n",
    "        reports_df_train = pd.concat([reports_df_train, report_df_train])\n",
    "\n",
    "# Export the DataFrames containing classification reports to separate CSV files\n",
    "reports_df_test.to_csv('testing_classification_reports_PG_10.csv', index=True)\n",
    "reports_df_train.to_csv('training_classification_reports_PG_10.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
