{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hvplot.pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Allow for reviewing more of the DataFrames\n",
    "pd.set_option('display.max_rows', 2000)\n",
    "pd.set_option('display.max_columns', 2000)\n",
    "pd.set_option('display.width', 1000)\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the fundamentals.csv file into a Pandas DataFrame\n",
    "df_fundamentals_csv = pd.read_csv(\"Resources/fundamentals.csv\", \n",
    "                                  infer_datetime_format=True,index_col=\"Date\",\n",
    "                                  parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get rows between two dates\n",
    "df_sliced = df_fundamentals_csv['2019':'2024']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column_names list of the desired columns\n",
    "column_names = ['GOOGL Adj. Close', 'GOOGL P/S (LTM)', 'GOOGL P/FCF (LTM)',\n",
    "       'GOOGL P/E (LTM)', 'GOOGL Debt/Equity (LTM)', 'NVDA Adj. Close',\n",
    "       'NVDA P/S (LTM)', 'NVDA P/FCF (LTM)', 'NVDA P/E (LTM)',\n",
    "       'NVDA Debt/Equity (LTM)', 'MMM Adj. Close', 'MMM P/S (LTM)',\n",
    "       'MMM P/FCF (LTM)', 'MMM P/E (LTM)', 'MMM Debt/Equity (LTM)',\n",
    "       'PG Adj. Close', 'PG P/S (LTM)', 'PG P/FCF (LTM)', 'PG P/E (LTM)',\n",
    "       'PG Debt/Equity (LTM)']\n",
    "\n",
    "# Copy the desired columns into a new DataFrame, df_final\n",
    "df_final = df_sliced[column_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write cleaned DataFrame to a CSV file (includes null values related to balance sheet data)\n",
    "df_final.to_csv('Resources/df_final.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate DataFrames for each stock\n",
    "googl_df = df_final[[\"GOOGL Adj. Close\", \"GOOGL P/S (LTM)\",\"GOOGL P/FCF (LTM)\",\"GOOGL P/E (LTM)\",\"GOOGL Debt/Equity (LTM)\"]]\n",
    "nvda_df = df_final[[\"NVDA Adj. Close\", \"NVDA P/S (LTM)\",\"NVDA P/FCF (LTM)\",\"NVDA P/E (LTM)\",\"NVDA Debt/Equity (LTM)\"]]\n",
    "mmm_df =  df_final[[\"MMM Adj. Close\", \"MMM P/S (LTM)\",\"MMM P/FCF (LTM)\",\"MMM P/E (LTM)\",\"MMM Debt/Equity (LTM)\"]]\n",
    "pg_df = df_final[[\"PG Adj. Close\", \"PG P/S (LTM)\",\"PG P/FCF (LTM)\",\"PG P/E (LTM)\",\"PG Debt/Equity (LTM)\"]]\n",
    "\n",
    "# Drop null values from each DataFrame's Adj. Close column (necessary for correct generation of SMAs, EMAs, BBands, and RSI)\n",
    "googl_df.dropna(subset=[\"GOOGL Adj. Close\"], inplace=True)\n",
    "nvda_df.dropna(subset=[\"NVDA Adj. Close\"], inplace=True)\n",
    "mmm_df.dropna(subset=[\"MMM Adj. Close\"], inplace=True)\n",
    "pg_df.dropna(subset=[\"PG Adj. Close\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of individual stock DataFrame names and columns to feed loops\n",
    "ticker_data = [(googl_df, \"GOOGL Adj. Close\"),(nvda_df, \"NVDA Adj. Close\"),(mmm_df, \"MMM Adj. Close\"),(pg_df, \"PG Adj. Close\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop to add actual_returns column based on percentage change\n",
    "for df_name, column_name in ticker_data:\n",
    "    df_name[\"actual_returns\"] = df_name[column_name].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop to Generate SMA and EMA columns (10-, 30-, 100-day windows) for each stock\n",
    "for df_name, column_name in ticker_data:\n",
    "    df_name[\"sma_fast\"] = df_name[column_name].rolling(window=10).mean()\n",
    "    df_name[\"sma_fast30\"] = df_name[column_name].rolling(window=30).mean()\n",
    "    df_name[\"sma_slow\"] = df_name[column_name].rolling(window=100).mean()\n",
    "    df_name[\"ema_fast\"] = df_name[column_name].ewm(span=10, adjust=False).mean()\n",
    "    df_name[\"ema_fast30\"] = df_name[column_name].ewm(span=30, adjust=False).mean()\n",
    "    df_name[\"ema_slow\"] = df_name[column_name].ewm(span=100, adjust=False).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing individual stock DataFrames with SMA and EMA (10-, 30-, 100-day windows) to Resources folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write individual stock DFs w/ SMA, EMA,  to CSV\n",
    "googl_df.to_csv('Resources/googl_df.csv', index=True)\n",
    "nvda_df.to_csv('Resources/nvda_df.csv', index=True)\n",
    "mmm_df.to_csv('Resources/mmm_df.csv', index=True)\n",
    "pg_df.to_csv('Resources/pg_df.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algotrading",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
